{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Yolov5 high resolution training\n\n### Major modification\n* img=3600\n* mixup=0.5\n* fliplr: 0.5\n\n### Hardware to reproduce\n* RTX3090","metadata":{}},{"cell_type":"markdown","source":"### Training Log:\n> ```\nversion=1\nimg_size:3584,bs2,e11,[yolov5s6] \nFold: video2[validation]\nLabels: only GT\n```","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:53:12.91626Z","iopub.execute_input":"2022-02-11T22:53:12.917182Z","iopub.status.idle":"2022-02-11T22:53:13.626978Z","shell.execute_reply.started":"2022-02-11T22:53:12.917075Z","shell.execute_reply":"2022-02-11T22:53:13.626226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom shutil import copyfile\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-11T22:53:13.630362Z","iopub.execute_input":"2022-02-11T22:53:13.63058Z","iopub.status.idle":"2022-02-11T22:53:13.634787Z","shell.execute_reply.started":"2022-02-11T22:53:13.630554Z","shell.execute_reply":"2022-02-11T22:53:13.634121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = pd.read_csv('../input/tensorflow-great-barrier-reef/train.csv')\n# train['pos'] = train.annotations != '[]'","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:53:13.635937Z","iopub.execute_input":"2022-02-11T22:53:13.636802Z","iopub.status.idle":"2022-02-11T22:53:13.645874Z","shell.execute_reply.started":"2022-02-11T22:53:13.636763Z","shell.execute_reply":"2022-02-11T22:53:13.645175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tensorflow-great-barrier-reef/train.csv\")\n\n# Turn annotations from strings into lists of dictionaries\ndf['annotations1'] = df['annotations'].apply(eval)\n\n# Create the image path for the row\ndf['image_path'] = \"video_\" + df['video_id'].astype(str) + \"/\" + df['video_frame'].astype(str) + \".jpg\"\n\nlength = lambda x: len(x) \n\ndf[\"no_of_bbox\"] = df[\"annotations1\"].apply(length)\n\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:53:13.648137Z","iopub.execute_input":"2022-02-11T22:53:13.64873Z","iopub.status.idle":"2022-02-11T22:53:14.098019Z","shell.execute_reply.started":"2022-02-11T22:53:13.64869Z","shell.execute_reply":"2022-02-11T22:53:14.09731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = df[df[\"video_id\"]==2][df[\"no_of_bbox\"]>0]\nval_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:53:14.099201Z","iopub.execute_input":"2022-02-11T22:53:14.099539Z","iopub.status.idle":"2022-02-11T22:53:14.115671Z","shell.execute_reply.started":"2022-02-11T22:53:14.099492Z","shell.execute_reply":"2022-02-11T22:53:14.114924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df[df[\"video_id\"]!=2][df[\"no_of_bbox\"]>0]\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:53:14.117126Z","iopub.execute_input":"2022-02-11T22:53:14.117625Z","iopub.status.idle":"2022-02-11T22:53:14.129226Z","shell.execute_reply.started":"2022-02-11T22:53:14.117588Z","shell.execute_reply":"2022-02-11T22:53:14.128466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p ./yolo_data/fold2/images/val\n!mkdir -p ./yolo_data/fold2/images/train\n\n!mkdir -p ./yolo_data/fold2/labels/val\n!mkdir -p ./yolo_data/fold2/labels/train","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:53:14.130586Z","iopub.execute_input":"2022-02-11T22:53:14.131032Z","iopub.status.idle":"2022-02-11T22:53:16.717713Z","shell.execute_reply.started":"2022-02-11T22:53:14.130997Z","shell.execute_reply":"2022-02-11T22:53:16.716702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 2\n\nannos = []\nfor i, x in val_df.iterrows():\n#     if x.video_id == fold:\n#         if x.pos:\n    mode = 'val'\n#     else:\n#         # train\n#         mode = 'train'\n#         if not x.pos: continue\n        # val\n    copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n                f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n#     if not x.pos:\n#         continue\n    r = ''\n    anno = eval(x.annotations)\n    for an in anno:\n#            annos.append(an)\n        r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n                                        (an['y'] + an['height'] / 2) / 720,\n                                        an['width'] / 1280, an['height'] / 720)\n    with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n        fp.write(r)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:53:16.720249Z","iopub.execute_input":"2022-02-11T22:53:16.720497Z","iopub.status.idle":"2022-02-11T22:53:24.857227Z","shell.execute_reply.started":"2022-02-11T22:53:16.720468Z","shell.execute_reply":"2022-02-11T22:53:24.856411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 2\n\nannos = []\nfor i, x in train_df.iterrows():\n#     if x.video_id == fold:\n#         if x.pos:\n    mode = 'train'\n#     else:\n#         # train\n#         mode = 'train'\n#         if not x.pos: continue\n        # val\n    copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n                f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n#     if not x.pos:\n#         continue\n    r = ''\n    anno = eval(x.annotations)\n    for an in anno:\n#            annos.append(an)\n        r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n                                        (an['y'] + an['height'] / 2) / 720,\n                                        an['width'] / 1280, an['height'] / 720)\n    with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n        fp.write(r)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:53:24.858507Z","iopub.execute_input":"2022-02-11T22:53:24.858792Z","iopub.status.idle":"2022-02-11T22:54:11.390758Z","shell.execute_reply.started":"2022-02-11T22:53:24.858746Z","shell.execute_reply":"2022-02-11T22:54:11.389962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold = 1\n\n# annos = []\n# for i, x in train.iterrows():\n#     if x.video_id == fold:\n#         if x.pos:\n#             mode = 'val'\n#     else:\n#         # train\n#         mode = 'train'\n#         if not x.pos: continue\n#         # val\n#     copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n#                 f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n#     if not x.pos:\n#         continue\n#     r = ''\n#     anno = eval(x.annotations)\n#     for an in anno:\n# #            annos.append(an)\n#         r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n#                                         (an['y'] + an['height'] / 2) / 720,\n#                                         an['width'] / 1280, an['height'] / 720)\n#     with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n#         fp.write(r)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-11T22:54:11.393977Z","iopub.execute_input":"2022-02-11T22:54:11.394338Z","iopub.status.idle":"2022-02-11T22:54:11.398346Z","shell.execute_reply.started":"2022-02-11T22:54:11.394299Z","shell.execute_reply":"2022-02-11T22:54:11.397691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nlen(os.listdir(\"./yolo_data/fold2/labels/train\"))","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:54:11.399655Z","iopub.execute_input":"2022-02-11T22:54:11.400118Z","iopub.status.idle":"2022-02-11T22:54:11.726158Z","shell.execute_reply.started":"2022-02-11T22:54:11.400083Z","shell.execute_reply":"2022-02-11T22:54:11.725305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyps = '''\n# YOLOv5 by Ultralytics, GPL-3.0 license\n# Hyperparameters for COCO training from scratch\n# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n\nlr0: 0.001  # initial learning rate (SGD=1E-2, Adam=1E-3)\nlrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)\nmomentum: 0.937  # SGD momentum/Adam beta1\nweight_decay: 0.0005  # optimizer weight decay 5e-4\nwarmup_epochs: 3.0  # warmup epochs (fractions ok)\nwarmup_momentum: 0.8  # warmup initial momentum\nwarmup_bias_lr: 0.1  # warmup initial bias lr\nbox: 0.05  # box loss gain\ncls: 0.5  # cls loss gain\ncls_pw: 1.0  # cls BCELoss positive_weight\nobj: 1.0  # obj loss gain (scale with pixels)\nobj_pw: 1.0  # obj BCELoss positive_weight\niou_t: 0.20  # IoU training threshold\nanchor_t: 4.0  # anchor-multiple threshold\n# anchors: 3  # anchors per output layer (0 to ignore)\nfl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\nhsv_h: 0.015  # image HSV-Hue augmentation (fraction)\nhsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\nhsv_v: 0.4  # image HSV-Value augmentation (fraction)\ndegrees: 0.0  # image rotation (+/- deg)\ntranslate: 0.1  # image translation (+/- fraction)\nscale: 0.5  # image scale (+/- gain)\nshear: 0.0  # image shear (+/- deg)\nperspective: 0.0  # image perspective (+/- fraction), range 0-0.001\nflipud: 0.5  # image flip up-down (probability)\nfliplr: 0.5  # image flip left-right (probability)\nmosaic: 1.0  # image mosaic (probability)\nmixup: 0.5  # image mixup (probability)\ncopy_paste: 0.0  # segment copy-paste (probability)\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:54:11.727863Z","iopub.execute_input":"2022-02-11T22:54:11.728632Z","iopub.status.idle":"2022-02-11T22:54:11.734899Z","shell.execute_reply.started":"2022-02-11T22:54:11.728589Z","shell.execute_reply":"2022-02-11T22:54:11.73398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = '''\n# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n\npath: ../yolo_data/fold2/  # dataset root dir\ntrain: images/train  # train images (relative to 'path') 128 images\nval: images/val  # val images (relative to 'path') 128 images\ntest:  # test images (optional)\n\n# Classes\nnc: 1  # number of classes\nnames: ['reef']  # class names\n\n\n# Download script/URL (optional)\n# download: https://ultralytics.com/assets/coco128.zip\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:54:11.736254Z","iopub.execute_input":"2022-02-11T22:54:11.736555Z","iopub.status.idle":"2022-02-11T22:54:11.747107Z","shell.execute_reply.started":"2022-02-11T22:54:11.73652Z","shell.execute_reply":"2022-02-11T22:54:11.746452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !git clone https://github.com/ultralytics/yolov5.git\n!git clone https://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@github.com/soumya997/yolov5-w-f2-mod.git\n!mv ./yolov5-w-f2-mod ./yolov5","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:54:11.748472Z","iopub.execute_input":"2022-02-11T22:54:11.748753Z","iopub.status.idle":"2022-02-11T22:54:14.98817Z","shell.execute_reply.started":"2022-02-11T22:54:11.748717Z","shell.execute_reply":"2022-02-11T22:54:14.987225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./yolov5/data/reef_f1_naive.yaml', 'w') as fp:\n    fp.write(data)\nwith open('./yolov5/data/hyps/hyp.heavy.2.yaml', 'w') as fp:\n    fp.write(hyps)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:54:14.989912Z","iopub.execute_input":"2022-02-11T22:54:14.990173Z","iopub.status.idle":"2022-02-11T22:54:14.996213Z","shell.execute_reply.started":"2022-02-11T22:54:14.990137Z","shell.execute_reply":"2022-02-11T22:54:14.995485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd yolov5","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:54:14.997542Z","iopub.execute_input":"2022-02-11T22:54:14.997859Z","iopub.status.idle":"2022-02-11T22:54:15.007619Z","shell.execute_reply.started":"2022-02-11T22:54:14.997751Z","shell.execute_reply":"2022-02-11T22:54:15.006891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls data/","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:54:15.008986Z","iopub.execute_input":"2022-02-11T22:54:15.009253Z","iopub.status.idle":"2022-02-11T22:54:15.671098Z","shell.execute_reply.started":"2022-02-11T22:54:15.00922Z","shell.execute_reply":"2022-02-11T22:54:15.670296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m wandb disabled\n\n!python train.py \\\n    --img 3000 \\\n    --batch 2 \\\n    --epochs 11 \\\n    --optimizer Adam \\\n    --data data/reef_f1_naive.yaml \\\n    --weights yolov5m6.pt \\\n    --name base_vid_2val \\\n    --hyp data/hyps/hyp.heavy.2.yaml \\\n    --save-period 1","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:54:15.672941Z","iopub.execute_input":"2022-02-11T22:54:15.673232Z","iopub.status.idle":"2022-02-11T23:08:16.23287Z","shell.execute_reply.started":"2022-02-11T22:54:15.673194Z","shell.execute_reply":"2022-02-11T23:08:16.232013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !python train.py ","metadata":{"execution":{"iopub.status.busy":"2022-02-11T23:08:16.237097Z","iopub.execute_input":"2022-02-11T23:08:16.237833Z","iopub.status.idle":"2022-02-11T23:08:31.789432Z","shell.execute_reply.started":"2022-02-11T23:08:16.237795Z","shell.execute_reply":"2022-02-11T23:08:31.788534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !python -m wandb disabled\n\n# !python train.py \\\n#     --img 3000 \\\n#     --batch 2 \\\n#     --epochs 11 \\\n#     --data data/reef_f1_naive.yaml \\\n#     --weights yolov5s6.pt \\\n#     --name cots_with_albs \\\n#     --hyp data/hyps/hyp.heavy.2.yaml \\\n#     --save-period 1","metadata":{"execution":{"iopub.status.busy":"2022-02-11T23:08:31.790753Z","iopub.execute_input":"2022-02-11T23:08:31.791013Z","iopub.status.idle":"2022-02-11T23:08:31.801148Z","shell.execute_reply.started":"2022-02-11T23:08:31.790979Z","shell.execute_reply":"2022-02-11T23:08:31.80049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-02-11T23:08:31.802946Z","iopub.execute_input":"2022-02-11T23:08:31.804359Z","iopub.status.idle":"2022-02-11T23:08:32.506668Z","shell.execute_reply.started":"2022-02-11T23:08:31.80431Z","shell.execute_reply":"2022-02-11T23:08:32.505767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %cd /kaggle/working\n\n# !cp -r /kaggle/working/yolov5/runs/train/base_vid_2val /kaggle/working\n\n# !cp /kaggle/working/yolov5/data/reef_f1_naive.yaml /kaggle/working/base_vid_2val/\n# !cp /kaggle/working/yolov5/data/hyps/hyp.heavy.2.yaml /kaggle/working/base_vid_2val/\n# # !cp /kaggle/working/yolov5/utils/augmentations.py /kaggle/working/base_vid_2val/\n\n# !rm -r /kaggle/working/yolov5\n# !rm -r /kaggle/working/images\n# !rm -r /kaggle/working/labels","metadata":{"execution":{"iopub.status.busy":"2022-02-11T23:08:32.510118Z","iopub.execute_input":"2022-02-11T23:08:32.510362Z","iopub.status.idle":"2022-02-11T23:08:36.461965Z","shell.execute_reply.started":"2022-02-11T23:08:32.510321Z","shell.execute_reply":"2022-02-11T23:08:36.461115Z"},"trusted":true},"execution_count":null,"outputs":[]}]}