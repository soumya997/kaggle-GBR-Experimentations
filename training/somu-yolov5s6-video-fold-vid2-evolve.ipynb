{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Yolov5 high resolution training\n\n### Major modification\n* img=3600\n* mixup=0.5\n* fliplr: 0.5\n\n### Hardware to reproduce\n* RTX3090","metadata":{}},{"cell_type":"markdown","source":"### Training Log:\n> ```\nversion=1\nimg_size:3584,bs2,e11,[yolov5s6] \nFold: video2[validation]\nLabels: only GT\n```","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:57:02.794495Z","iopub.execute_input":"2022-02-11T21:57:02.794788Z","iopub.status.idle":"2022-02-11T21:57:03.668383Z","shell.execute_reply.started":"2022-02-11T21:57:02.794757Z","shell.execute_reply":"2022-02-11T21:57:03.667256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom shutil import copyfile\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-11T21:57:03.672163Z","iopub.execute_input":"2022-02-11T21:57:03.676830Z","iopub.status.idle":"2022-02-11T21:57:03.684969Z","shell.execute_reply.started":"2022-02-11T21:57:03.676783Z","shell.execute_reply":"2022-02-11T21:57:03.683958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = pd.read_csv('../input/tensorflow-great-barrier-reef/train.csv')\n# train['pos'] = train.annotations != '[]'","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:57:03.690161Z","iopub.execute_input":"2022-02-11T21:57:03.692214Z","iopub.status.idle":"2022-02-11T21:57:03.698010Z","shell.execute_reply.started":"2022-02-11T21:57:03.692153Z","shell.execute_reply":"2022-02-11T21:57:03.696968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tensorflow-great-barrier-reef/train.csv\")\n\n# Turn annotations from strings into lists of dictionaries\ndf['annotations1'] = df['annotations'].apply(eval)\n\n# Create the image path for the row\ndf['image_path'] = \"video_\" + df['video_id'].astype(str) + \"/\" + df['video_frame'].astype(str) + \".jpg\"\n\nlength = lambda x: len(x) \n\ndf[\"no_of_bbox\"] = df[\"annotations1\"].apply(length)\n\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:57:03.700487Z","iopub.execute_input":"2022-02-11T21:57:03.701324Z","iopub.status.idle":"2022-02-11T21:57:04.273754Z","shell.execute_reply.started":"2022-02-11T21:57:03.701277Z","shell.execute_reply":"2022-02-11T21:57:04.272812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = df[df[\"video_id\"]==2][df[\"no_of_bbox\"]>0]\nval_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:57:04.276988Z","iopub.execute_input":"2022-02-11T21:57:04.277392Z","iopub.status.idle":"2022-02-11T21:57:04.299873Z","shell.execute_reply.started":"2022-02-11T21:57:04.277343Z","shell.execute_reply":"2022-02-11T21:57:04.298875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df[df[\"video_id\"]!=2][df[\"no_of_bbox\"]>0]\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:57:04.301525Z","iopub.execute_input":"2022-02-11T21:57:04.302065Z","iopub.status.idle":"2022-02-11T21:57:04.316400Z","shell.execute_reply.started":"2022-02-11T21:57:04.302022Z","shell.execute_reply":"2022-02-11T21:57:04.315295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p ./yolo_data/fold2/images/val\n!mkdir -p ./yolo_data/fold2/images/train\n\n!mkdir -p ./yolo_data/fold2/labels/val\n!mkdir -p ./yolo_data/fold2/labels/train","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:57:04.318661Z","iopub.execute_input":"2022-02-11T21:57:04.319748Z","iopub.status.idle":"2022-02-11T21:57:07.247225Z","shell.execute_reply.started":"2022-02-11T21:57:04.319703Z","shell.execute_reply":"2022-02-11T21:57:07.245874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 2\n\nannos = []\nfor i, x in val_df.iterrows():\n#     if x.video_id == fold:\n#         if x.pos:\n    mode = 'val'\n#     else:\n#         # train\n#         mode = 'train'\n#         if not x.pos: continue\n        # val\n    copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n                f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n#     if not x.pos:\n#         continue\n    r = ''\n    anno = eval(x.annotations)\n    for an in anno:\n#            annos.append(an)\n        r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n                                        (an['y'] + an['height'] / 2) / 720,\n                                        an['width'] / 1280, an['height'] / 720)\n    with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n        fp.write(r)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:57:07.250426Z","iopub.execute_input":"2022-02-11T21:57:07.251198Z","iopub.status.idle":"2022-02-11T21:57:16.014109Z","shell.execute_reply.started":"2022-02-11T21:57:07.251130Z","shell.execute_reply":"2022-02-11T21:57:16.013095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 2\n\nannos = []\nfor i, x in train_df.iterrows():\n#     if x.video_id == fold:\n#         if x.pos:\n    mode = 'train'\n#     else:\n#         # train\n#         mode = 'train'\n#         if not x.pos: continue\n        # val\n    copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n                f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n#     if not x.pos:\n#         continue\n    r = ''\n    anno = eval(x.annotations)\n    for an in anno:\n#            annos.append(an)\n        r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n                                        (an['y'] + an['height'] / 2) / 720,\n                                        an['width'] / 1280, an['height'] / 720)\n    with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n        fp.write(r)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:57:16.015910Z","iopub.execute_input":"2022-02-11T21:57:16.016269Z","iopub.status.idle":"2022-02-11T21:58:06.540328Z","shell.execute_reply.started":"2022-02-11T21:57:16.016226Z","shell.execute_reply":"2022-02-11T21:58:06.539224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold = 1\n\n# annos = []\n# for i, x in train.iterrows():\n#     if x.video_id == fold:\n#         if x.pos:\n#             mode = 'val'\n#     else:\n#         # train\n#         mode = 'train'\n#         if not x.pos: continue\n#         # val\n#     copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n#                 f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n#     if not x.pos:\n#         continue\n#     r = ''\n#     anno = eval(x.annotations)\n#     for an in anno:\n# #            annos.append(an)\n#         r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n#                                         (an['y'] + an['height'] / 2) / 720,\n#                                         an['width'] / 1280, an['height'] / 720)\n#     with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n#         fp.write(r)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-11T21:58:06.544390Z","iopub.execute_input":"2022-02-11T21:58:06.545938Z","iopub.status.idle":"2022-02-11T21:58:06.550343Z","shell.execute_reply.started":"2022-02-11T21:58:06.544803Z","shell.execute_reply":"2022-02-11T21:58:06.549414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nlen(os.listdir(\"./yolo_data/fold2/labels/train\"))","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:58:06.551781Z","iopub.execute_input":"2022-02-11T21:58:06.552878Z","iopub.status.idle":"2022-02-11T21:58:06.572633Z","shell.execute_reply.started":"2022-02-11T21:58:06.552819Z","shell.execute_reply":"2022-02-11T21:58:06.571315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyps = '''\n# YOLOv5 by Ultralytics, GPL-3.0 license\n# Hyperparameters for COCO training from scratch\n# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n\nlr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\nlrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)\nmomentum: 0.937  # SGD momentum/Adam beta1\nweight_decay: 0.0005  # optimizer weight decay 5e-4\nwarmup_epochs: 3.0  # warmup epochs (fractions ok)\nwarmup_momentum: 0.8  # warmup initial momentum\nwarmup_bias_lr: 0.1  # warmup initial bias lr\nbox: 0.05  # box loss gain\ncls: 0.5  # cls loss gain\ncls_pw: 1.0  # cls BCELoss positive_weight\nobj: 1.0  # obj loss gain (scale with pixels)\nobj_pw: 1.0  # obj BCELoss positive_weight\niou_t: 0.20  # IoU training threshold\nanchor_t: 4.0  # anchor-multiple threshold\n# anchors: 3  # anchors per output layer (0 to ignore)\nfl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\nhsv_h: 0.015  # image HSV-Hue augmentation (fraction)\nhsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\nhsv_v: 0.4  # image HSV-Value augmentation (fraction)\ndegrees: 0.0  # image rotation (+/- deg)\ntranslate: 0.1  # image translation (+/- fraction)\nscale: 0.5  # image scale (+/- gain)\nshear: 0.0  # image shear (+/- deg)\nperspective: 0.0  # image perspective (+/- fraction), range 0-0.001\nflipud: 0.5  # image flip up-down (probability)\nfliplr: 0.5  # image flip left-right (probability)\nmosaic: 1.0  # image mosaic (probability)\nmixup: 0.5  # image mixup (probability)\ncopy_paste: 0.0  # segment copy-paste (probability)\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:58:06.574477Z","iopub.execute_input":"2022-02-11T21:58:06.575392Z","iopub.status.idle":"2022-02-11T21:58:06.582962Z","shell.execute_reply.started":"2022-02-11T21:58:06.575345Z","shell.execute_reply":"2022-02-11T21:58:06.581656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = '''\n# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n\npath: ../yolo_data/fold2/  # dataset root dir\ntrain: images/train  # train images (relative to 'path') 128 images\nval: images/val  # val images (relative to 'path') 128 images\ntest:  # test images (optional)\n\n# Classes\nnc: 1  # number of classes\nnames: ['reef']  # class names\n\n\n# Download script/URL (optional)\n# download: https://ultralytics.com/assets/coco128.zip\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:58:06.585209Z","iopub.execute_input":"2022-02-11T21:58:06.585616Z","iopub.status.idle":"2022-02-11T21:58:06.597185Z","shell.execute_reply.started":"2022-02-11T21:58:06.585574Z","shell.execute_reply":"2022-02-11T21:58:06.596096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !git clone https://github.com/ultralytics/yolov5.git\n!git clone https://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@github.com/soumya997/yolov5-w-f2-mod.git\n!mv ./yolov5-w-f2-mod ./yolov5","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:58:06.602187Z","iopub.execute_input":"2022-02-11T21:58:06.602430Z","iopub.status.idle":"2022-02-11T21:58:09.727677Z","shell.execute_reply.started":"2022-02-11T21:58:06.602401Z","shell.execute_reply":"2022-02-11T21:58:09.726471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./yolov5/data/reef_f1_naive.yaml', 'w') as fp:\n    fp.write(data)\nwith open('./yolov5/data/hyps/hyp.heavy.2.yaml', 'w') as fp:\n    fp.write(hyps)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:58:09.733093Z","iopub.execute_input":"2022-02-11T21:58:09.735499Z","iopub.status.idle":"2022-02-11T21:58:09.744172Z","shell.execute_reply.started":"2022-02-11T21:58:09.735435Z","shell.execute_reply":"2022-02-11T21:58:09.743183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd yolov5","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:58:09.749971Z","iopub.execute_input":"2022-02-11T21:58:09.750649Z","iopub.status.idle":"2022-02-11T21:58:09.763704Z","shell.execute_reply.started":"2022-02-11T21:58:09.750605Z","shell.execute_reply":"2022-02-11T21:58:09.762484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls data/","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:58:09.766423Z","iopub.execute_input":"2022-02-11T21:58:09.768038Z","iopub.status.idle":"2022-02-11T21:58:10.572952Z","shell.execute_reply.started":"2022-02-11T21:58:09.767991Z","shell.execute_reply":"2022-02-11T21:58:10.571838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train.py \\\n    --img 1280 \\\n    --batch 2 \\\n    --epochs 10 \\\n    --data data/reef_f1_naive.yaml \\\n    --weights yolov5s6.pt \\\n    --cache \\\n    --evolve 100","metadata":{"execution":{"iopub.status.busy":"2022-02-11T21:58:10.576356Z","iopub.execute_input":"2022-02-11T21:58:10.576586Z","iopub.status.idle":"2022-02-11T22:00:47.478356Z","shell.execute_reply.started":"2022-02-11T21:58:10.576555Z","shell.execute_reply":"2022-02-11T22:00:47.467732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !python -m wandb disabled\n\n# !python train.py \\\n#     --img 3584 \\\n#     --batch 2 \\\n#     --epochs 11 \\\n#     --data data/reef_f1_naive.yaml \\\n#     --weights yolov5s6.pt \\\n#     --name base_vid_2val \\\n#     --hyp data/hyps/hyp.heavy.2.yaml \\\n#     --save-period 1","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:00:47.490279Z","iopub.execute_input":"2022-02-11T22:00:47.490570Z","iopub.status.idle":"2022-02-11T22:00:47.502289Z","shell.execute_reply.started":"2022-02-11T22:00:47.490527Z","shell.execute_reply":"2022-02-11T22:00:47.501359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !python -m wandb disabled\n\n# !python train.py \\\n#     --img 3000 \\\n#     --batch 2 \\\n#     --epochs 11 \\\n#     --data data/reef_f1_naive.yaml \\\n#     --weights yolov5s6.pt \\\n#     --name cots_with_albs \\\n#     --hyp data/hyps/hyp.heavy.2.yaml \\\n#     --save-period 1","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:00:47.503863Z","iopub.execute_input":"2022-02-11T22:00:47.504551Z","iopub.status.idle":"2022-02-11T22:00:47.538611Z","shell.execute_reply.started":"2022-02-11T22:00:47.504485Z","shell.execute_reply":"2022-02-11T22:00:47.537501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:00:47.539898Z","iopub.execute_input":"2022-02-11T22:00:47.540230Z","iopub.status.idle":"2022-02-11T22:00:48.735033Z","shell.execute_reply.started":"2022-02-11T22:00:47.540187Z","shell.execute_reply":"2022-02-11T22:00:48.733969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\n\n!cp -r /kaggle/working/yolov5/runs/train/base_vid_2val /kaggle/working\n\n!cp /kaggle/working/yolov5/data/reef_f1_naive.yaml /kaggle/working/base_vid_2val/\n!cp /kaggle/working/yolov5/data/hyps/hyp.heavy.2.yaml /kaggle/working/base_vid_2val/\n# !cp /kaggle/working/yolov5/utils/augmentations.py /kaggle/working/base_vid_2val/\n\n!rm -r /kaggle/working/yolov5\n!rm -r /kaggle/working/images\n!rm -r /kaggle/working/labels","metadata":{"execution":{"iopub.status.busy":"2022-02-11T22:00:48.737125Z","iopub.execute_input":"2022-02-11T22:00:48.739671Z","iopub.status.idle":"2022-02-11T22:00:53.131171Z","shell.execute_reply.started":"2022-02-11T22:00:48.739621Z","shell.execute_reply":"2022-02-11T22:00:53.130077Z"},"trusted":true},"execution_count":null,"outputs":[]}]}