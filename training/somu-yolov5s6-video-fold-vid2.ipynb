{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Yolov5 high resolution training\n\n### Major modification\n* img=3600\n* mixup=0.5\n* fliplr: 0.5\n\n### Hardware to reproduce\n* RTX3090","metadata":{}},{"cell_type":"markdown","source":"### Training Log:\n> ```\nversion=1\nimg_size:3584,bs2,e11,[yolov5s6] \nFold: video2[validation]\nLabels: only GT\n```","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:11:26.336024Z","iopub.execute_input":"2022-02-08T14:11:26.336665Z","iopub.status.idle":"2022-02-08T14:11:27.065832Z","shell.execute_reply.started":"2022-02-08T14:11:26.336551Z","shell.execute_reply":"2022-02-08T14:11:27.064984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom shutil import copyfile\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-08T14:11:27.067993Z","iopub.execute_input":"2022-02-08T14:11:27.068207Z","iopub.status.idle":"2022-02-08T14:11:27.072496Z","shell.execute_reply.started":"2022-02-08T14:11:27.068181Z","shell.execute_reply":"2022-02-08T14:11:27.071802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = pd.read_csv('../input/tensorflow-great-barrier-reef/train.csv')\n# train['pos'] = train.annotations != '[]'","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:11:27.073787Z","iopub.execute_input":"2022-02-08T14:11:27.074262Z","iopub.status.idle":"2022-02-08T14:11:27.084071Z","shell.execute_reply.started":"2022-02-08T14:11:27.074227Z","shell.execute_reply":"2022-02-08T14:11:27.08322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tensorflow-great-barrier-reef/train.csv\")\n\n# Turn annotations from strings into lists of dictionaries\ndf['annotations1'] = df['annotations'].apply(eval)\n\n# Create the image path for the row\ndf['image_path'] = \"video_\" + df['video_id'].astype(str) + \"/\" + df['video_frame'].astype(str) + \".jpg\"\n\nlength = lambda x: len(x) \n\ndf[\"no_of_bbox\"] = df[\"annotations1\"].apply(length)\n\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:11:27.086308Z","iopub.execute_input":"2022-02-08T14:11:27.086966Z","iopub.status.idle":"2022-02-08T14:11:27.550776Z","shell.execute_reply.started":"2022-02-08T14:11:27.086928Z","shell.execute_reply":"2022-02-08T14:11:27.550095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = df[df[\"video_id\"]==2][df[\"no_of_bbox\"]>0]\nval_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:11:27.552152Z","iopub.execute_input":"2022-02-08T14:11:27.552633Z","iopub.status.idle":"2022-02-08T14:11:27.568233Z","shell.execute_reply.started":"2022-02-08T14:11:27.552586Z","shell.execute_reply":"2022-02-08T14:11:27.567371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df[df[\"video_id\"]!=2][df[\"no_of_bbox\"]>0]\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:11:27.569687Z","iopub.execute_input":"2022-02-08T14:11:27.569938Z","iopub.status.idle":"2022-02-08T14:11:27.582258Z","shell.execute_reply.started":"2022-02-08T14:11:27.569905Z","shell.execute_reply":"2022-02-08T14:11:27.581361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p ./yolo_data/fold2/images/val\n!mkdir -p ./yolo_data/fold2/images/train\n\n!mkdir -p ./yolo_data/fold2/labels/val\n!mkdir -p ./yolo_data/fold2/labels/train","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:11:27.583657Z","iopub.execute_input":"2022-02-08T14:11:27.584087Z","iopub.status.idle":"2022-02-08T14:11:30.233792Z","shell.execute_reply.started":"2022-02-08T14:11:27.584054Z","shell.execute_reply":"2022-02-08T14:11:30.232924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 2\n\nannos = []\nfor i, x in val_df.iterrows():\n#     if x.video_id == fold:\n#         if x.pos:\n    mode = 'val'\n#     else:\n#         # train\n#         mode = 'train'\n#         if not x.pos: continue\n        # val\n    copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n                f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n#     if not x.pos:\n#         continue\n    r = ''\n    anno = eval(x.annotations)\n    for an in anno:\n#            annos.append(an)\n        r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n                                        (an['y'] + an['height'] / 2) / 720,\n                                        an['width'] / 1280, an['height'] / 720)\n    with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n        fp.write(r)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:11:30.237165Z","iopub.execute_input":"2022-02-08T14:11:30.237414Z","iopub.status.idle":"2022-02-08T14:11:39.720024Z","shell.execute_reply.started":"2022-02-08T14:11:30.237384Z","shell.execute_reply":"2022-02-08T14:11:39.719275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 2\n\nannos = []\nfor i, x in train_df.iterrows():\n#     if x.video_id == fold:\n#         if x.pos:\n    mode = 'train'\n#     else:\n#         # train\n#         mode = 'train'\n#         if not x.pos: continue\n        # val\n    copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n                f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n#     if not x.pos:\n#         continue\n    r = ''\n    anno = eval(x.annotations)\n    for an in anno:\n#            annos.append(an)\n        r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n                                        (an['y'] + an['height'] / 2) / 720,\n                                        an['width'] / 1280, an['height'] / 720)\n    with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n        fp.write(r)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:11:39.723369Z","iopub.execute_input":"2022-02-08T14:11:39.723598Z","iopub.status.idle":"2022-02-08T14:12:25.080677Z","shell.execute_reply.started":"2022-02-08T14:11:39.723573Z","shell.execute_reply":"2022-02-08T14:12:25.079945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold = 1\n\n# annos = []\n# for i, x in train.iterrows():\n#     if x.video_id == fold:\n#         if x.pos:\n#             mode = 'val'\n#     else:\n#         # train\n#         mode = 'train'\n#         if not x.pos: continue\n#         # val\n#     copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n#                 f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n#     if not x.pos:\n#         continue\n#     r = ''\n#     anno = eval(x.annotations)\n#     for an in anno:\n# #            annos.append(an)\n#         r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n#                                         (an['y'] + an['height'] / 2) / 720,\n#                                         an['width'] / 1280, an['height'] / 720)\n#     with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n#         fp.write(r)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-08T14:12:25.084559Z","iopub.execute_input":"2022-02-08T14:12:25.085085Z","iopub.status.idle":"2022-02-08T14:12:25.090891Z","shell.execute_reply.started":"2022-02-08T14:12:25.085053Z","shell.execute_reply":"2022-02-08T14:12:25.090234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nlen(os.listdir(\"./yolo_data/fold2/labels/train\"))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:12:25.09233Z","iopub.execute_input":"2022-02-08T14:12:25.092613Z","iopub.status.idle":"2022-02-08T14:12:25.108411Z","shell.execute_reply.started":"2022-02-08T14:12:25.092573Z","shell.execute_reply":"2022-02-08T14:12:25.107803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyps = '''\n# YOLOv5 by Ultralytics, GPL-3.0 license\n# Hyperparameters for COCO training from scratch\n# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n\nlr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\nlrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)\nmomentum: 0.937  # SGD momentum/Adam beta1\nweight_decay: 0.0005  # optimizer weight decay 5e-4\nwarmup_epochs: 3.0  # warmup epochs (fractions ok)\nwarmup_momentum: 0.8  # warmup initial momentum\nwarmup_bias_lr: 0.1  # warmup initial bias lr\nbox: 0.05  # box loss gain\ncls: 0.5  # cls loss gain\ncls_pw: 1.0  # cls BCELoss positive_weight\nobj: 1.0  # obj loss gain (scale with pixels)\nobj_pw: 1.0  # obj BCELoss positive_weight\niou_t: 0.20  # IoU training threshold\nanchor_t: 4.0  # anchor-multiple threshold\n# anchors: 3  # anchors per output layer (0 to ignore)\nfl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\nhsv_h: 0.015  # image HSV-Hue augmentation (fraction)\nhsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\nhsv_v: 0.4  # image HSV-Value augmentation (fraction)\ndegrees: 0.0  # image rotation (+/- deg)\ntranslate: 0.1  # image translation (+/- fraction)\nscale: 0.5  # image scale (+/- gain)\nshear: 0.0  # image shear (+/- deg)\nperspective: 0.0  # image perspective (+/- fraction), range 0-0.001\nflipud: 0.5  # image flip up-down (probability)\nfliplr: 0.5  # image flip left-right (probability)\nmosaic: 1.0  # image mosaic (probability)\nmixup: 0.5  # image mixup (probability)\ncopy_paste: 0.0  # segment copy-paste (probability)\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:12:25.109647Z","iopub.execute_input":"2022-02-08T14:12:25.109895Z","iopub.status.idle":"2022-02-08T14:12:25.117037Z","shell.execute_reply.started":"2022-02-08T14:12:25.109864Z","shell.execute_reply":"2022-02-08T14:12:25.116356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = '''\n# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n\npath: ../yolo_data/fold2/  # dataset root dir\ntrain: images/train  # train images (relative to 'path') 128 images\nval: images/val  # val images (relative to 'path') 128 images\ntest:  # test images (optional)\n\n# Classes\nnc: 1  # number of classes\nnames: ['reef']  # class names\n\n\n# Download script/URL (optional)\n# download: https://ultralytics.com/assets/coco128.zip\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:12:25.11803Z","iopub.execute_input":"2022-02-08T14:12:25.11861Z","iopub.status.idle":"2022-02-08T14:12:25.125969Z","shell.execute_reply.started":"2022-02-08T14:12:25.118579Z","shell.execute_reply":"2022-02-08T14:12:25.125306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !git clone https://github.com/ultralytics/yolov5.git\n!git clone https://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@github.com/soumya997/yolov5-w-f2-mod.git\n!mv ./yolov5-w-f2-mod ./yolov5","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:12:25.127113Z","iopub.execute_input":"2022-02-08T14:12:25.127827Z","iopub.status.idle":"2022-02-08T14:12:27.098611Z","shell.execute_reply.started":"2022-02-08T14:12:25.127802Z","shell.execute_reply":"2022-02-08T14:12:27.0977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./yolov5/data/reef_f1_naive.yaml', 'w') as fp:\n    fp.write(data)\nwith open('./yolov5/data/hyps/hyp.heavy.2.yaml', 'w') as fp:\n    fp.write(hyps)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:12:27.100719Z","iopub.execute_input":"2022-02-08T14:12:27.10113Z","iopub.status.idle":"2022-02-08T14:12:27.106864Z","shell.execute_reply.started":"2022-02-08T14:12:27.101081Z","shell.execute_reply":"2022-02-08T14:12:27.106045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd yolov5","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:12:27.108167Z","iopub.execute_input":"2022-02-08T14:12:27.108587Z","iopub.status.idle":"2022-02-08T14:12:27.11741Z","shell.execute_reply.started":"2022-02-08T14:12:27.108552Z","shell.execute_reply":"2022-02-08T14:12:27.116592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls data/","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:12:27.118757Z","iopub.execute_input":"2022-02-08T14:12:27.119079Z","iopub.status.idle":"2022-02-08T14:12:27.88926Z","shell.execute_reply.started":"2022-02-08T14:12:27.119041Z","shell.execute_reply":"2022-02-08T14:12:27.888253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m wandb disabled\n\n!python train.py \\\n    --img 3584 \\\n    --batch 2 \\\n    --epochs 11 \\\n    --data data/reef_f1_naive.yaml \\\n    --weights yolov5s6.pt \\\n    --name base_vid_2val \\\n    --hyp data/hyps/hyp.heavy.2.yaml \\\n    --save-period 1","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:12:27.89441Z","iopub.execute_input":"2022-02-08T14:12:27.894701Z","iopub.status.idle":"2022-02-08T14:23:51.194617Z","shell.execute_reply.started":"2022-02-08T14:12:27.894661Z","shell.execute_reply":"2022-02-08T14:23:51.193753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !python -m wandb disabled\n\n# !python train.py \\\n#     --img 3000 \\\n#     --batch 2 \\\n#     --epochs 11 \\\n#     --data data/reef_f1_naive.yaml \\\n#     --weights yolov5s6.pt \\\n#     --name cots_with_albs \\\n#     --hyp data/hyps/hyp.heavy.2.yaml \\\n#     --save-period 1","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:23:51.198124Z","iopub.execute_input":"2022-02-08T14:23:51.198368Z","iopub.status.idle":"2022-02-08T14:23:51.202001Z","shell.execute_reply.started":"2022-02-08T14:23:51.198335Z","shell.execute_reply":"2022-02-08T14:23:51.201372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:23:51.20345Z","iopub.execute_input":"2022-02-08T14:23:51.203997Z","iopub.status.idle":"2022-02-08T14:23:51.875843Z","shell.execute_reply.started":"2022-02-08T14:23:51.203961Z","shell.execute_reply":"2022-02-08T14:23:51.874985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\n\n!cp -r /kaggle/working/yolov5/runs/train/base_vid_2val /kaggle/working\n\n!cp /kaggle/working/yolov5/data/reef_f1_naive.yaml /kaggle/working/base_vid_2val/\n!cp /kaggle/working/yolov5/data/hyps/hyp.heavy.2.yaml /kaggle/working/base_vid_2val/\n# !cp /kaggle/working/yolov5/utils/augmentations.py /kaggle/working/base_vid_2val/\n\n!rm -r /kaggle/working/yolov5\n!rm -r /kaggle/working/images\n!rm -r /kaggle/working/labels","metadata":{},"execution_count":null,"outputs":[]}]}