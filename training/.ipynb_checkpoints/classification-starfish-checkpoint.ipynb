{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3687a2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:37.635864Z",
     "iopub.status.busy": "2022-02-09T23:11:37.634334Z",
     "iopub.status.idle": "2022-02-09T23:11:41.363153Z",
     "shell.execute_reply": "2022-02-09T23:11:41.362533Z",
     "shell.execute_reply.started": "2022-02-09T23:08:02.131404Z"
    },
    "papermill": {
     "duration": 3.752369,
     "end_time": "2022-02-09T23:11:41.363314",
     "exception": false,
     "start_time": "2022-02-09T23:11:37.610945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import random\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "import torchvision # torch package for vision related things\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "# import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f8c451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:41.406806Z",
     "iopub.status.busy": "2022-02-09T23:11:41.402997Z",
     "iopub.status.idle": "2022-02-09T23:11:41.467577Z",
     "shell.execute_reply": "2022-02-09T23:11:41.466859Z",
     "shell.execute_reply.started": "2022-02-09T23:08:05.845715Z"
    },
    "papermill": {
     "duration": 0.085138,
     "end_time": "2022-02-09T23:11:41.467703",
     "exception": false,
     "start_time": "2022-02-09T23:11:41.382565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "# https://www.kaggle.com/sarques/intel-image-classification-using-pytorch\n",
    "def set_seed(seed = 1234):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "#     random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) # gpu vars\n",
    "    if torch.backends.cudnn.is_available:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae91ed6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:41.514430Z",
     "iopub.status.busy": "2022-02-09T23:11:41.513710Z",
     "iopub.status.idle": "2022-02-09T23:11:41.516843Z",
     "shell.execute_reply": "2022-02-09T23:11:41.517278Z",
     "shell.execute_reply.started": "2022-02-09T23:08:05.897788Z"
    },
    "papermill": {
     "duration": 0.029931,
     "end_time": "2022-02-09T23:11:41.517402",
     "exception": false,
     "start_time": "2022-02-09T23:11:41.487471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "in_channels = 3\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7550c3d5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:41.560021Z",
     "iopub.status.busy": "2022-02-09T23:11:41.557641Z",
     "iopub.status.idle": "2022-02-09T23:11:42.450664Z",
     "shell.execute_reply": "2022-02-09T23:11:42.450242Z",
     "shell.execute_reply.started": "2022-02-09T23:08:05.915309Z"
    },
    "papermill": {
     "duration": 0.914969,
     "end_time": "2022-02-09T23:11:42.450791",
     "exception": false,
     "start_time": "2022-02-09T23:11:41.535822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/binary-cropped-crown-of-thorns-d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/binary-cropped-crown-of-thorns-d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/binary-cropped-crown-of-thorns-d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/binary-cropped-crown-of-thorns-d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/binary-cropped-crown-of-thorns-d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  labels\n",
       "0  /kaggle/input/binary-cropped-crown-of-thorns-d...       0\n",
       "1  /kaggle/input/binary-cropped-crown-of-thorns-d...       0\n",
       "2  /kaggle/input/binary-cropped-crown-of-thorns-d...       0\n",
       "3  /kaggle/input/binary-cropped-crown-of-thorns-d...       0\n",
       "4  /kaggle/input/binary-cropped-crown-of-thorns-d...       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR = \"/kaggle/input/binary-cropped-crown-of-thorns-dataset/\"\n",
    "cot_img = [DIR + \"cots_crops/\" + i for i in os.listdir(DIR+\"cots_crops\")]\n",
    "nocot_img = [DIR + \"notcots_crops/\" + i for i in os.listdir(DIR+\"notcots_crops\")]\n",
    "\n",
    "cot_lab = list(np.zeros((len(cot_img),)).astype(np.int8)) # cot = 0\n",
    "# cot_lab\n",
    "nocot_lab = list(np.ones((len(nocot_img),)).astype(np.int8)) # nocot = 1\n",
    "\n",
    "imgs = cot_img + nocot_img\n",
    "labels = cot_lab + nocot_lab\n",
    "\n",
    "# len(labels),len(imgs)\n",
    "df_dict = {\"img_path\": imgs, \"labels\":labels}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95803911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:42.492542Z",
     "iopub.status.busy": "2022-02-09T23:11:42.491859Z",
     "iopub.status.idle": "2022-02-09T23:11:42.615042Z",
     "shell.execute_reply": "2022-02-09T23:11:42.614562Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.451786Z"
    },
    "papermill": {
     "duration": 0.145563,
     "end_time": "2022-02-09T23:11:42.615163",
     "exception": false,
     "start_time": "2022-02-09T23:11:42.469600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"bin_cropped_cots.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "388e95b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:42.663156Z",
     "iopub.status.busy": "2022-02-09T23:11:42.662489Z",
     "iopub.status.idle": "2022-02-09T23:11:42.665053Z",
     "shell.execute_reply": "2022-02-09T23:11:42.665456Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.578687Z"
    },
    "papermill": {
     "duration": 0.031428,
     "end_time": "2022-02-09T23:11:42.665573",
     "exception": false,
     "start_time": "2022-02-09T23:11:42.634145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11898\n",
       "1    11898\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c30e21c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:42.707942Z",
     "iopub.status.busy": "2022-02-09T23:11:42.707132Z",
     "iopub.status.idle": "2022-02-09T23:11:42.709841Z",
     "shell.execute_reply": "2022-02-09T23:11:42.710345Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.594369Z"
    },
    "papermill": {
     "duration": 0.026184,
     "end_time": "2022-02-09T23:11:42.710461",
     "exception": false,
     "start_time": "2022-02-09T23:11:42.684277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"labels\"].iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd9d0cac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:42.751229Z",
     "iopub.status.busy": "2022-02-09T23:11:42.750426Z",
     "iopub.status.idle": "2022-02-09T23:11:42.757382Z",
     "shell.execute_reply": "2022-02-09T23:11:42.756944Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.604085Z"
    },
    "papermill": {
     "duration": 0.028061,
     "end_time": "2022-02-09T23:11:42.757483",
     "exception": false,
     "start_time": "2022-02-09T23:11:42.729422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class cot_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transform=None):\n",
    "\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_path = self.df[\"img_path\"].iloc[index]\n",
    "#         print(img_path)\n",
    "        image = cv2.imread(img_path)\n",
    "#         print(image.shape)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        y_label = torch.tensor(int(self.df[\"labels\"].iloc[index]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "#             transformed = self.transform(image=image)\n",
    "#             image = transformed[\"image\"]\n",
    "        \n",
    "        return image, y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af80b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:42.799600Z",
     "iopub.status.busy": "2022-02-09T23:11:42.798763Z",
     "iopub.status.idle": "2022-02-09T23:11:42.803120Z",
     "shell.execute_reply": "2022-02-09T23:11:42.803536Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.613804Z"
    },
    "papermill": {
     "duration": 0.025754,
     "end_time": "2022-02-09T23:11:42.803650",
     "exception": false,
     "start_time": "2022-02-09T23:11:42.777896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    return T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Resize((50,50))\n",
    "    ])\n",
    "\n",
    "# def get_transform():\n",
    "#     return A.Compose([\n",
    "#         ToTensorV2(1.0),\n",
    "#         A.Resize(50,50,p=1.0)\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffe952e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:42.847789Z",
     "iopub.status.busy": "2022-02-09T23:11:42.847280Z",
     "iopub.status.idle": "2022-02-09T23:11:42.854268Z",
     "shell.execute_reply": "2022-02-09T23:11:42.853798Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.625880Z"
    },
    "papermill": {
     "duration": 0.031397,
     "end_time": "2022-02-09T23:11:42.854370",
     "exception": false,
     "start_time": "2022-02-09T23:11:42.822973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, val_df = split(df,test_size=0.33, random_state=42)\n",
    "\n",
    "train_ds = cot_Dataset(train_df,get_transform())\n",
    "val_ds = cot_Dataset(val_df,get_transform())\n",
    "\n",
    "# val_df.shape\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2feeb37c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:42.896430Z",
     "iopub.status.busy": "2022-02-09T23:11:42.895804Z",
     "iopub.status.idle": "2022-02-09T23:11:43.163500Z",
     "shell.execute_reply": "2022-02-09T23:11:43.164147Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.637966Z"
    },
    "papermill": {
     "duration": 0.291016,
     "end_time": "2022-02-09T23:11:43.164302",
     "exception": false,
     "start_time": "2022-02-09T23:11:42.873286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc5e9892d50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, lab = train_ds[12]\n",
    "print(lab)\n",
    "plt.imshow(img.permute(2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56e1fb0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:43.209904Z",
     "iopub.status.busy": "2022-02-09T23:11:43.209256Z",
     "iopub.status.idle": "2022-02-09T23:11:43.214678Z",
     "shell.execute_reply": "2022-02-09T23:11:43.215097Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.902935Z"
    },
    "papermill": {
     "duration": 0.030283,
     "end_time": "2022-02-09T23:11:43.215232",
     "exception": false,
     "start_time": "2022-02-09T23:11:43.184949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(dataset = train_ds, batch_size = batch_size, shuffle=True, num_workers=4)\n",
    "val_dl = DataLoader(dataset = val_ds, batch_size = batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e3d768",
   "metadata": {
    "papermill": {
     "duration": 0.020628,
     "end_time": "2022-02-09T23:11:43.256342",
     "exception": false,
     "start_time": "2022-02-09T23:11:43.235714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# get image norm values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de80c3b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:43.301760Z",
     "iopub.status.busy": "2022-02-09T23:11:43.301147Z",
     "iopub.status.idle": "2022-02-09T23:11:43.303361Z",
     "shell.execute_reply": "2022-02-09T23:11:43.303730Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.913468Z"
    },
    "papermill": {
     "duration": 0.026955,
     "end_time": "2022-02-09T23:11:43.303878",
     "exception": false,
     "start_time": "2022-02-09T23:11:43.276923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mean=[0.485, 0.456, 0.406],\n",
    "# std=[0.229, 0.224, 0.225]\n",
    "\n",
    "# norm_ds = cot_Dataset(df)\n",
    "# norm_dl = DataLoader(dataset = norm_ds, batch_size = 1, shuffle=True, num_workers=4)\n",
    "\n",
    "# transform = A.Compose([\n",
    "#      ToTensorV2(p=1.0)\n",
    "# ])\n",
    "\n",
    "# mean_list = []\n",
    "# std_list = []\n",
    "# for i in tqdm(range(len(norm_ds))):\n",
    "#     img = norm_ds[i][0]\n",
    "    \n",
    "#     transformed = transform(image=img)[\"image\"] # shape [chn,height,width]\n",
    "#     mean, std = transformed.mean([0,2]).tolist(), transformed.std([0,2]).tolist()\n",
    "# #     print(transformed.mean([0,2]).shape)\n",
    "# #     break\n",
    "#     mean_list.append(mean)\n",
    "#     std_list.append(std)\n",
    "    \n",
    "# # print mean and std\n",
    "# print(\"mean and std before normalize:\")\n",
    "# print(\"Mean of the image:\", np.mean(mean_list,axis=0))\n",
    "# print(\"Std of the image:\", np.mean(std_list,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41f41396",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:43.348937Z",
     "iopub.status.busy": "2022-02-09T23:11:43.348421Z",
     "iopub.status.idle": "2022-02-09T23:11:43.352039Z",
     "shell.execute_reply": "2022-02-09T23:11:43.351566Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.923290Z"
    },
    "papermill": {
     "duration": 0.027509,
     "end_time": "2022-02-09T23:11:43.352147",
     "exception": false,
     "start_time": "2022-02-09T23:11:43.324638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# size_set = set()\n",
    "# for i,x in tqdm(df.iterrows()):\n",
    "#     img_path = x.img_path\n",
    "#     size_set.add(plt.imread(img_path).shape)\n",
    "# print(size_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aba6f62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:43.397434Z",
     "iopub.status.busy": "2022-02-09T23:11:43.396939Z",
     "iopub.status.idle": "2022-02-09T23:11:43.406625Z",
     "shell.execute_reply": "2022-02-09T23:11:43.406242Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.931028Z"
    },
    "papermill": {
     "duration": 0.03378,
     "end_time": "2022-02-09T23:11:43.406735",
     "exception": false,
     "start_time": "2022-02-09T23:11:43.372955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##To read it again from file\n",
    "with open('../input/random-images-dataset/size_set.txt','rb') as f:\n",
    "    my_set = pickle.load(f)\n",
    "    \n",
    "# print(my_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1d58703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:43.457102Z",
     "iopub.status.busy": "2022-02-09T23:11:43.456405Z",
     "iopub.status.idle": "2022-02-09T23:11:43.459250Z",
     "shell.execute_reply": "2022-02-09T23:11:43.458788Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.943151Z"
    },
    "papermill": {
     "duration": 0.03178,
     "end_time": "2022-02-09T23:11:43.459350",
     "exception": false,
     "start_time": "2022-02-09T23:11:43.427570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=8,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=8,\n",
    "            out_channels=16,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(2304, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8da2467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:43.504529Z",
     "iopub.status.busy": "2022-02-09T23:11:43.503740Z",
     "iopub.status.idle": "2022-02-09T23:11:43.505624Z",
     "shell.execute_reply": "2022-02-09T23:11:43.506043Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.954242Z"
    },
    "papermill": {
     "duration": 0.026224,
     "end_time": "2022-02-09T23:11:43.506174",
     "exception": false,
     "start_time": "2022-02-09T23:11:43.479950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "# import torch.nn as nn\n",
    "# def build_model(pretrained=True, fine_tune=True, num_classes=10):\n",
    "#     if pretrained:\n",
    "#         print('[INFO]: Loading pre-trained weights')\n",
    "#     else:\n",
    "#         print('[INFO]: Not loading pre-trained weights')\n",
    "#     model = models.efficientnet_b0(pretrained=pretrained)\n",
    "#     if fine_tune:\n",
    "#         print('[INFO]: Fine-tuning all layers...')\n",
    "#         for params in model.parameters():\n",
    "#             params.requires_grad = True\n",
    "#     elif not fine_tune:\n",
    "#         print('[INFO]: Freezing hidden layers...')\n",
    "#         for params in model.parameters():\n",
    "#             params.requires_grad = False\n",
    "#     # Change the final classification head.\n",
    "#     model.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83223a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:43.552823Z",
     "iopub.status.busy": "2022-02-09T23:11:43.552316Z",
     "iopub.status.idle": "2022-02-09T23:11:46.466386Z",
     "shell.execute_reply": "2022-02-09T23:11:46.465432Z",
     "shell.execute_reply.started": "2022-02-09T23:08:06.964521Z"
    },
    "papermill": {
     "duration": 2.939797,
     "end_time": "2022-02-09T23:11:46.466534",
     "exception": false,
     "start_time": "2022-02-09T23:11:43.526737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize network\n",
    "model = CNN(in_channels=in_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "707a8e5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:46.515547Z",
     "iopub.status.busy": "2022-02-09T23:11:46.514689Z",
     "iopub.status.idle": "2022-02-09T23:11:46.517347Z",
     "shell.execute_reply": "2022-02-09T23:11:46.516907Z",
     "shell.execute_reply.started": "2022-02-09T23:08:09.775770Z"
    },
    "papermill": {
     "duration": 0.029245,
     "end_time": "2022-02-09T23:11:46.517463",
     "exception": false,
     "start_time": "2022-02-09T23:11:46.488218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = build_model(\n",
    "#         pretrained=True,\n",
    "#         fine_tune=True, \n",
    "#         num_classes=len(dataset_classes)\n",
    "#     ).to(device)\n",
    "    \n",
    "# # Total parameters and trainable parameters.\n",
    "# total_params = sum(p.numel() for p in model.parameters())\n",
    "# print(f\"{total_params:,} total parameters.\")\n",
    "# total_trainable_params = sum(\n",
    "#     p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# print(f\"{total_trainable_params:,} training parameters.\")\n",
    "# # Optimizer.\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# # Loss function.\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "056b436a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:46.566873Z",
     "iopub.status.busy": "2022-02-09T23:11:46.566291Z",
     "iopub.status.idle": "2022-02-09T23:11:46.570150Z",
     "shell.execute_reply": "2022-02-09T23:11:46.569714Z",
     "shell.execute_reply.started": "2022-02-09T23:08:09.782882Z"
    },
    "papermill": {
     "duration": 0.030516,
     "end_time": "2022-02-09T23:11:46.570269",
     "exception": false,
     "start_time": "2022-02-09T23:11:46.539753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(true,pred):\n",
    "    pred = F.softmax(pred, dim = 1)\n",
    "    true = torch.zeros(pred.shape[0], pred.shape[1]).scatter_(1, true.unsqueeze(1), 1.)\n",
    "    acc = (true.argmax(-1) == pred.argmax(-1)).float().detach().numpy()\n",
    "    acc = float((100 * acc.sum()) / len(acc))\n",
    "    return round(acc, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ed82ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:46.617842Z",
     "iopub.status.busy": "2022-02-09T23:11:46.617187Z",
     "iopub.status.idle": "2022-02-09T23:11:46.619800Z",
     "shell.execute_reply": "2022-02-09T23:11:46.619405Z",
     "shell.execute_reply.started": "2022-02-09T23:08:09.795410Z"
    },
    "papermill": {
     "duration": 0.028172,
     "end_time": "2022-02-09T23:11:46.619933",
     "exception": false,
     "start_time": "2022-02-09T23:11:46.591761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(epoch, model, optimizer, path):\n",
    "    \"\"\"\n",
    "    Function to save the trained model till current epoch, or whenver called\n",
    "    \"\"\"\n",
    "    torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b38c7c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:11:46.673648Z",
     "iopub.status.busy": "2022-02-09T23:11:46.673097Z",
     "iopub.status.idle": "2022-02-09T23:17:32.051327Z",
     "shell.execute_reply": "2022-02-09T23:17:32.052027Z",
     "shell.execute_reply.started": "2022-02-09T23:08:55.559562Z"
    },
    "papermill": {
     "duration": 345.411421,
     "end_time": "2022-02-09T23:17:32.052234",
     "exception": false,
     "start_time": "2022-02-09T23:11:46.640813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################  [1/20]  ####################\n",
      "** Epoch 1/20 ** - Epoch Time 0.7256 min  | Train Loss = 0.466  Train Accuracy = 77.88970801603206 %  |  Val Loss = 0.3842  |  Val Accuracy = 82.29264390243904 % \n",
      "\n",
      "####################  [2/20]  ####################\n",
      "** Epoch 2/20 ** - Epoch Time 0.2688 min  | Train Loss = 0.3123  Train Accuracy = 86.50425851703407 %  |  Val Loss = 0.2988  |  Val Accuracy = 87.18925894308943 % \n",
      "\n",
      "####################  [3/20]  ####################\n",
      "** Epoch 3/20 ** - Epoch Time 0.2589 min  | Train Loss = 0.2392  Train Accuracy = 90.11415691382766 %  |  Val Loss = 0.2329  |  Val Accuracy = 90.51164796747969 % \n",
      "\n",
      "####################  [4/20]  ####################\n",
      "** Epoch 4/20 ** - Epoch Time 0.2629 min  | Train Loss = 0.222  Train Accuracy = 91.01953907815631 %  |  Val Loss = 0.2115  |  Val Accuracy = 91.42041910569105 % \n",
      "\n",
      "####################  [5/20]  ####################\n",
      "** Epoch 5/20 ** - Epoch Time 0.2642 min  | Train Loss = 0.2072  Train Accuracy = 91.58942885771543 %  |  Val Loss = 0.191  |  Val Accuracy = 92.30964674796748 % \n",
      "\n",
      "####################  [6/20]  ####################\n",
      "** Epoch 6/20 ** - Epoch Time 0.2655 min  | Train Loss = 0.1924  Train Accuracy = 92.21568136272545 %  |  Val Loss = 0.2099  |  Val Accuracy = 91.74972642276421 % \n",
      "\n",
      "####################  [7/20]  ####################\n",
      "** Epoch 7/20 ** - Epoch Time 0.2638 min  | Train Loss = 0.1837  Train Accuracy = 92.56012024048096 %  |  Val Loss = 0.1966  |  Val Accuracy = 92.30182926829268 % \n",
      "\n",
      "####################  [8/20]  ####################\n",
      "** Epoch 8/20 ** - Epoch Time 0.2626 min  | Train Loss = 0.1785  Train Accuracy = 92.76320501002004 %  |  Val Loss = 0.1844  |  Val Accuracy = 92.49335528455286 % \n",
      "\n",
      "####################  [9/20]  ####################\n",
      "** Epoch 9/20 ** - Epoch Time 0.2623 min  | Train Loss = 0.1705  Train Accuracy = 93.01996853707415 %  |  Val Loss = 0.1825  |  Val Accuracy = 92.75328333333333 % \n",
      "\n",
      "####################  [10/20]  ####################\n",
      "** Epoch 10/20 ** - Epoch Time 0.2666 min  | Train Loss = 0.1667  Train Accuracy = 93.46192384769539 %  |  Val Loss = 0.1727  |  Val Accuracy = 93.07086463414633 % \n",
      "\n",
      "####################  [11/20]  ####################\n",
      "** Epoch 11/20 ** - Epoch Time 0.2646 min  | Train Loss = 0.1568  Train Accuracy = 93.8940380761523 %  |  Val Loss = 0.1665  |  Val Accuracy = 93.49691219512196 % \n",
      "\n",
      "####################  [12/20]  ####################\n",
      "** Epoch 12/20 ** - Epoch Time 0.2676 min  | Train Loss = 0.1497  Train Accuracy = 94.16332665330661 %  |  Val Loss = 0.1609  |  Val Accuracy = 93.8135162601626 % \n",
      "\n",
      "####################  [13/20]  ####################\n",
      "** Epoch 13/20 ** - Epoch Time 0.2626 min  | Train Loss = 0.1474  Train Accuracy = 94.30736472945891 %  |  Val Loss = 0.1597  |  Val Accuracy = 94.31578333333333 % \n",
      "\n",
      "####################  [14/20]  ####################\n",
      "** Epoch 14/20 ** - Epoch Time 0.2682 min  | Train Loss = 0.1396  Train Accuracy = 94.81731322645291 %  |  Val Loss = 0.1511  |  Val Accuracy = 94.02947154471545 % \n",
      "\n",
      "####################  [15/20]  ####################\n",
      "** Epoch 15/20 ** - Epoch Time 0.2594 min  | Train Loss = 0.1402  Train Accuracy = 94.38251503006012 %  |  Val Loss = 0.1392  |  Val Accuracy = 94.44867886178862 % \n",
      "\n",
      "####################  [16/20]  ####################\n",
      "** Epoch 16/20 ** - Epoch Time 0.278 min  | Train Loss = 0.1291  Train Accuracy = 95.20290581162325 %  |  Val Loss = 0.1433  |  Val Accuracy = 94.56984837398373 % \n",
      "\n",
      "####################  [17/20]  ####################\n",
      "** Epoch 17/20 ** - Epoch Time 0.263 min  | Train Loss = 0.1281  Train Accuracy = 94.87099198396794 %  |  Val Loss = 0.1433  |  Val Accuracy = 94.51317235772359 % \n",
      "\n",
      "####################  [18/20]  ####################\n",
      "** Epoch 18/20 ** - Epoch Time 0.2655 min  | Train Loss = 0.1233  Train Accuracy = 95.27179358717434 %  |  Val Loss = 0.1701  |  Val Accuracy = 93.29268292682927 % \n",
      "\n",
      "####################  [19/20]  ####################\n",
      "** Epoch 19/20 ** - Epoch Time 0.256 min  | Train Loss = 0.1258  Train Accuracy = 95.17785571142285 %  |  Val Loss = 0.1494  |  Val Accuracy = 94.20145406504064 % \n",
      "\n",
      "####################  [20/20]  ####################\n",
      "** Epoch 20/20 ** - Epoch Time 0.2692 min  | Train Loss = 0.1188  Train Accuracy = 95.54108216432866 %  |  Val Loss = 0.1487  |  Val Accuracy = 94.14380081300813 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Training Code\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"#\"*20 + f\"  [{epoch+1}/{num_epochs}]  \" + \"#\"*20)\n",
    "    start = time.time()\n",
    "    \n",
    "    #Epoch Loss & Accuracy\n",
    "    train_epoch_loss = []\n",
    "    train_epoch_accuracy = []\n",
    "    _iter = 1\n",
    "    \n",
    "    #Val Loss & Accuracy\n",
    "    val_epoch_loss = []\n",
    "    val_epoch_accuracy = []\n",
    "    \n",
    "    # Training\n",
    "    for images, labels in train_dl:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Reset Grads\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward ->\n",
    "        preds = model(images)\n",
    "        \n",
    "        #Calculate Accuracy\n",
    "        acc = calc_accuracy(labels.cpu(), preds.cpu())\n",
    "#         acc = check_accuracy(zip(images,labels.cpu()), model)\n",
    "        \n",
    "        #Calculate Loss & Backward, Update Weights (Step)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Append loss & acc\n",
    "        loss_value = loss.item()\n",
    "        train_epoch_loss.append(loss_value)\n",
    "        train_epoch_accuracy.append(acc)\n",
    "        \n",
    "        if _iter % 500 == 0:\n",
    "            print(f\"> Iteration {_iter} <  | Iter Loss = {round(loss_value, 4)}  | Iter Accuracy = {acc} % \\n\")\n",
    "            \n",
    "#             print(\"> Iteration {} < \".format(_iter))\n",
    "#             print(\"Iter Loss = {}\".format(round(loss_value, 4)))\n",
    "#             print(\"Iter Accuracy = {} % \\n\".format(acc))\n",
    "        \n",
    "        _iter += 1\n",
    "    \n",
    "    #Validation\n",
    "    for images, labels in val_dl:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward ->\n",
    "        preds = model(images)\n",
    "        \n",
    "        #Calculate Accuracy\n",
    "        acc = calc_accuracy(labels.cpu(), preds.cpu())\n",
    "        \n",
    "        #Calculate Loss\n",
    "        loss = criterion(preds, labels)\n",
    "        \n",
    "        #Append loss & acc\n",
    "        loss_value = loss.item()\n",
    "        val_epoch_loss.append(loss_value)\n",
    "        val_epoch_accuracy.append(acc)\n",
    "    \n",
    "    \n",
    "    train_epoch_loss = np.mean(train_epoch_loss)\n",
    "    train_epoch_accuracy = np.mean(train_epoch_accuracy)\n",
    "    \n",
    "    val_epoch_loss = np.mean(val_epoch_loss)\n",
    "    val_epoch_accuracy = np.mean(val_epoch_accuracy)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "#     train_loss.append(train_epoch_loss)\n",
    "#     train_accuracy.append(train_epoch_accuracy)\n",
    "    \n",
    "#     val_loss.append(val_epoch_loss)\n",
    "#     val_accuracy.append(val_epoch_accuracy)\n",
    "    \n",
    "    save_model(epoch, model, optimizer, f'cots_cnn_e{epoch}bs8.pt')\n",
    "    \n",
    "    #Print Epoch Statistics\n",
    "    print(f\"** Epoch {epoch+1}/{num_epochs} ** - Epoch Time {round((end-start)/60,4)} min  | Train Loss = {round(train_epoch_loss, 4)}  Train Accuracy = {train_epoch_accuracy} %  |  Val Loss = {round(val_epoch_loss, 4)}  |  Val Accuracy = {val_epoch_accuracy} % \\n\")\n",
    "#     print(\"** Epoch {} ** - Epoch Time {}\".format(epoch, int(end-start)))\n",
    "#     print(\"Train Loss = {}\".format(round(train_epoch_loss, 4)))\n",
    "#     print(\"Train Accuracy = {} % \\n\".format(train_epoch_accuracy))\n",
    "#     print(\"Val Loss = {}\".format(round(val_epoch_loss, 4)))\n",
    "#     print(\"Val Accuracy = {} % \\n\".format(val_epoch_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce0c9981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:17:32.111383Z",
     "iopub.status.busy": "2022-02-09T23:17:32.110382Z",
     "iopub.status.idle": "2022-02-09T23:17:32.114116Z",
     "shell.execute_reply": "2022-02-09T23:17:32.113666Z",
     "shell.execute_reply.started": "2022-02-09T23:08:15.900896Z"
    },
    "papermill": {
     "duration": 0.034787,
     "end_time": "2022-02-09T23:17:32.114240",
     "exception": false,
     "start_time": "2022-02-09T23:17:32.079453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Train Network\n",
    "# model.train()\n",
    "# train_loss = 0\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     time_start = time.time()\n",
    "#     loss_accum = 0\n",
    "#     for batch_idx, (data, targets) in enumerate(tqdm(train_dl)):\n",
    "#         # Get data to cuda if possible\n",
    "#         data = data.to(device=device)\n",
    "#         targets = targets.to(device=device)\n",
    "# #         print(data.shape)\n",
    "#         # forward\n",
    "#         scores = model(data)\n",
    "#         loss = criterion(scores, targets)\n",
    "        \n",
    "#         loss_value = loss.item()\n",
    "\n",
    "#         loss_accum += loss_value\n",
    "# #         train_loss += loss.item()\n",
    "        \n",
    "#         # backward\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "\n",
    "#         # gradient descent or adam step\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         # Print metrics so we see some progress\n",
    "# #         print('\\tTraining batch {} Loss: {:.6f}'.format(batch_idx + 1, loss.item()))\n",
    "            \n",
    "# #         # return average loss for the epoch\n",
    "# #         avg_loss = train_loss / (batch_idx+1)\n",
    "# #         print('Training set: Average loss: {:.6f}'.format(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b22a539",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T23:17:32.174042Z",
     "iopub.status.busy": "2022-02-09T23:17:32.172733Z",
     "iopub.status.idle": "2022-02-09T23:17:47.252678Z",
     "shell.execute_reply": "2022-02-09T23:17:47.251948Z",
     "shell.execute_reply.started": "2022-02-09T23:08:15.902716Z"
    },
    "papermill": {
     "duration": 15.112585,
     "end_time": "2022-02-09T23:17:47.252877",
     "exception": false,
     "start_time": "2022-02-09T23:17:32.140292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 95.40\n",
      "Accuracy on test set: 94.13\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy on training & test to see how good our model\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    return num_correct/num_samples\n",
    "\n",
    "\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_dl, model)*100:.2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(val_dl, model)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea5656",
   "metadata": {
    "papermill": {
     "duration": 0.026588,
     "end_time": "2022-02-09T23:17:47.307391",
     "exception": false,
     "start_time": "2022-02-09T23:17:47.280803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 380.540742,
   "end_time": "2022-02-09T23:17:49.721473",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-09T23:11:29.180731",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
