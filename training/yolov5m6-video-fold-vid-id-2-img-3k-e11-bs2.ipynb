{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Yolov5 high resolution training\n\n### Major modification\n* img=3600\n* mixup=0.5\n* fliplr: 0.5\n\n### Hardware to reproduce\n* RTX3090","metadata":{}},{"cell_type":"markdown","source":"### Training Log:\n> ```\nversion=1\nimg_size:3584,bs2,e11,[yolov5s6] \nFold: video2[validation]\nLabels: only GT\n```","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:53:13.666496Z","iopub.execute_input":"2022-02-10T20:53:13.667086Z","iopub.status.idle":"2022-02-10T20:53:14.377969Z","shell.execute_reply.started":"2022-02-10T20:53:13.66699Z","shell.execute_reply":"2022-02-10T20:53:14.377216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom shutil import copyfile\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-10T20:53:14.381432Z","iopub.execute_input":"2022-02-10T20:53:14.382037Z","iopub.status.idle":"2022-02-10T20:53:14.388293Z","shell.execute_reply.started":"2022-02-10T20:53:14.382005Z","shell.execute_reply":"2022-02-10T20:53:14.387595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = pd.read_csv('../input/tensorflow-great-barrier-reef/train.csv')\n# train['pos'] = train.annotations != '[]'","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:53:14.389279Z","iopub.execute_input":"2022-02-10T20:53:14.391302Z","iopub.status.idle":"2022-02-10T20:53:14.396477Z","shell.execute_reply.started":"2022-02-10T20:53:14.391265Z","shell.execute_reply":"2022-02-10T20:53:14.395722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tensorflow-great-barrier-reef/train.csv\")\n\n# Turn annotations from strings into lists of dictionaries\ndf['annotations1'] = df['annotations'].apply(eval)\n\n# Create the image path for the row\ndf['image_path'] = \"video_\" + df['video_id'].astype(str) + \"/\" + df['video_frame'].astype(str) + \".jpg\"\n\nlength = lambda x: len(x) \n\ndf[\"no_of_bbox\"] = df[\"annotations1\"].apply(length)\n\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:53:14.397934Z","iopub.execute_input":"2022-02-10T20:53:14.398453Z","iopub.status.idle":"2022-02-10T20:53:14.84267Z","shell.execute_reply.started":"2022-02-10T20:53:14.398416Z","shell.execute_reply":"2022-02-10T20:53:14.841995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = df[df[\"video_id\"]==2][df[\"no_of_bbox\"]>0]\nval_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:53:14.844998Z","iopub.execute_input":"2022-02-10T20:53:14.845479Z","iopub.status.idle":"2022-02-10T20:53:14.860407Z","shell.execute_reply.started":"2022-02-10T20:53:14.845443Z","shell.execute_reply":"2022-02-10T20:53:14.859735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df[df[\"video_id\"]!=2][df[\"no_of_bbox\"]>0]\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:53:14.861754Z","iopub.execute_input":"2022-02-10T20:53:14.862246Z","iopub.status.idle":"2022-02-10T20:53:14.872489Z","shell.execute_reply.started":"2022-02-10T20:53:14.86221Z","shell.execute_reply":"2022-02-10T20:53:14.871697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p ./yolo_data/fold2/images/val\n!mkdir -p ./yolo_data/fold2/images/train\n\n!mkdir -p ./yolo_data/fold2/labels/val\n!mkdir -p ./yolo_data/fold2/labels/train","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:53:14.873931Z","iopub.execute_input":"2022-02-10T20:53:14.874414Z","iopub.status.idle":"2022-02-10T20:53:17.517342Z","shell.execute_reply.started":"2022-02-10T20:53:14.874379Z","shell.execute_reply":"2022-02-10T20:53:17.516405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 2\n\nannos = []\nfor i, x in val_df.iterrows():\n#     if x.video_id == fold:\n#         if x.pos:\n    mode = 'val'\n#     else:\n#         # train\n#         mode = 'train'\n#         if not x.pos: continue\n        # val\n    copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n                f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n#     if not x.pos:\n#         continue\n    r = ''\n    anno = eval(x.annotations)\n    for an in anno:\n#            annos.append(an)\n        r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n                                        (an['y'] + an['height'] / 2) / 720,\n                                        an['width'] / 1280, an['height'] / 720)\n    with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n        fp.write(r)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:53:17.519315Z","iopub.execute_input":"2022-02-10T20:53:17.519935Z","iopub.status.idle":"2022-02-10T20:53:26.249839Z","shell.execute_reply.started":"2022-02-10T20:53:17.51989Z","shell.execute_reply":"2022-02-10T20:53:26.249116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 2\n\nannos = []\nfor i, x in train_df.iterrows():\n#     if x.video_id == fold:\n#         if x.pos:\n    mode = 'train'\n#     else:\n#         # train\n#         mode = 'train'\n#         if not x.pos: continue\n        # val\n    copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n                f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n#     if not x.pos:\n#         continue\n    r = ''\n    anno = eval(x.annotations)\n    for an in anno:\n#            annos.append(an)\n        r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n                                        (an['y'] + an['height'] / 2) / 720,\n                                        an['width'] / 1280, an['height'] / 720)\n    with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n        fp.write(r)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:53:26.251082Z","iopub.execute_input":"2022-02-10T20:53:26.251347Z","iopub.status.idle":"2022-02-10T20:54:15.406615Z","shell.execute_reply.started":"2022-02-10T20:53:26.251313Z","shell.execute_reply":"2022-02-10T20:54:15.405894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold = 1\n\n# annos = []\n# for i, x in train.iterrows():\n#     if x.video_id == fold:\n#         if x.pos:\n#             mode = 'val'\n#     else:\n#         # train\n#         mode = 'train'\n#         if not x.pos: continue\n#         # val\n#     copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n#                 f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n#     if not x.pos:\n#         continue\n#     r = ''\n#     anno = eval(x.annotations)\n#     for an in anno:\n# #            annos.append(an)\n#         r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n#                                         (an['y'] + an['height'] / 2) / 720,\n#                                         an['width'] / 1280, an['height'] / 720)\n#     with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n#         fp.write(r)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-10T20:54:15.407956Z","iopub.execute_input":"2022-02-10T20:54:15.40843Z","iopub.status.idle":"2022-02-10T20:54:15.413285Z","shell.execute_reply.started":"2022-02-10T20:54:15.408393Z","shell.execute_reply":"2022-02-10T20:54:15.41258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nlen(os.listdir(\"./yolo_data/fold2/labels/train\"))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:54:15.414497Z","iopub.execute_input":"2022-02-10T20:54:15.415157Z","iopub.status.idle":"2022-02-10T20:54:15.432244Z","shell.execute_reply.started":"2022-02-10T20:54:15.415119Z","shell.execute_reply":"2022-02-10T20:54:15.431582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyps = '''\n# YOLOv5 by Ultralytics, GPL-3.0 license\n# Hyperparameters for COCO training from scratch\n# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n\nlr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\nlrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)\nmomentum: 0.937  # SGD momentum/Adam beta1\nweight_decay: 0.0005  # optimizer weight decay 5e-4\nwarmup_epochs: 3.0  # warmup epochs (fractions ok)\nwarmup_momentum: 0.8  # warmup initial momentum\nwarmup_bias_lr: 0.1  # warmup initial bias lr\nbox: 0.05  # box loss gain\ncls: 0.5  # cls loss gain\ncls_pw: 1.0  # cls BCELoss positive_weight\nobj: 1.0  # obj loss gain (scale with pixels)\nobj_pw: 1.0  # obj BCELoss positive_weight\niou_t: 0.20  # IoU training threshold\nanchor_t: 4.0  # anchor-multiple threshold\n# anchors: 3  # anchors per output layer (0 to ignore)\nfl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\nhsv_h: 0.015  # image HSV-Hue augmentation (fraction)\nhsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\nhsv_v: 0.4  # image HSV-Value augmentation (fraction)\ndegrees: 0.0  # image rotation (+/- deg)\ntranslate: 0.1  # image translation (+/- fraction)\nscale: 0.5  # image scale (+/- gain)\nshear: 0.0  # image shear (+/- deg)\nperspective: 0.0  # image perspective (+/- fraction), range 0-0.001\nflipud: 0.5  # image flip up-down (probability)\nfliplr: 0.5  # image flip left-right (probability)\nmosaic: 1.0  # image mosaic (probability)\nmixup: 0.5  # image mixup (probability)\ncopy_paste: 0.0  # segment copy-paste (probability)\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:54:15.433519Z","iopub.execute_input":"2022-02-10T20:54:15.433788Z","iopub.status.idle":"2022-02-10T20:54:15.441385Z","shell.execute_reply.started":"2022-02-10T20:54:15.433752Z","shell.execute_reply":"2022-02-10T20:54:15.440656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = '''\n# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n\npath: ../yolo_data/fold2/  # dataset root dir\ntrain: images/train  # train images (relative to 'path') 128 images\nval: images/val  # val images (relative to 'path') 128 images\ntest:  # test images (optional)\n\n# Classes\nnc: 1  # number of classes\nnames: ['reef']  # class names\n\n\n# Download script/URL (optional)\n# download: https://ultralytics.com/assets/coco128.zip\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:54:15.442464Z","iopub.execute_input":"2022-02-10T20:54:15.44277Z","iopub.status.idle":"2022-02-10T20:54:15.451545Z","shell.execute_reply.started":"2022-02-10T20:54:15.442736Z","shell.execute_reply":"2022-02-10T20:54:15.450764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !git clone https://github.com/ultralytics/yolov5.git\n!git clone https://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@github.com/soumya997/yolov5-w-f2-mod.git\n!mv ./yolov5-w-f2-mod ./yolov5","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:54:15.455126Z","iopub.execute_input":"2022-02-10T20:54:15.455352Z","iopub.status.idle":"2022-02-10T20:54:19.179894Z","shell.execute_reply.started":"2022-02-10T20:54:15.455323Z","shell.execute_reply":"2022-02-10T20:54:19.178924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./yolov5/data/reef_f1_naive.yaml', 'w') as fp:\n    fp.write(data)\nwith open('./yolov5/data/hyps/hyp.heavy.2.yaml', 'w') as fp:\n    fp.write(hyps)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:54:19.181426Z","iopub.execute_input":"2022-02-10T20:54:19.18169Z","iopub.status.idle":"2022-02-10T20:54:19.187697Z","shell.execute_reply.started":"2022-02-10T20:54:19.181652Z","shell.execute_reply":"2022-02-10T20:54:19.186925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd yolov5","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:54:19.189243Z","iopub.execute_input":"2022-02-10T20:54:19.189482Z","iopub.status.idle":"2022-02-10T20:54:19.19859Z","shell.execute_reply.started":"2022-02-10T20:54:19.189451Z","shell.execute_reply":"2022-02-10T20:54:19.197836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls data/","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:54:19.199913Z","iopub.execute_input":"2022-02-10T20:54:19.200289Z","iopub.status.idle":"2022-02-10T20:54:19.856227Z","shell.execute_reply.started":"2022-02-10T20:54:19.200255Z","shell.execute_reply":"2022-02-10T20:54:19.855422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m wandb disabled\n\n!python train.py \\\n    --img 3000 \\\n    --batch 2 \\\n    --epochs 11 \\\n    --data data/reef_f1_naive.yaml \\\n    --weights yolov5m6.pt \\\n    --name M6_base_vid_2val \\\n    --hyp data/hyps/hyp.heavy.2.yaml \\\n    --save-period 1","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:54:19.857983Z","iopub.execute_input":"2022-02-10T20:54:19.858295Z","iopub.status.idle":"2022-02-10T20:59:21.638503Z","shell.execute_reply.started":"2022-02-10T20:54:19.858255Z","shell.execute_reply":"2022-02-10T20:59:21.637663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:59:21.641971Z","iopub.execute_input":"2022-02-10T20:59:21.642222Z","iopub.status.idle":"2022-02-10T20:59:22.415242Z","shell.execute_reply.started":"2022-02-10T20:59:21.64217Z","shell.execute_reply":"2022-02-10T20:59:22.41408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !python -m wandb disabled\n\n# !python train.py \\\n#     --img 3000 \\\n#     --batch 2 \\\n#     --epochs 11 \\\n#     --data data/reef_f1_naive.yaml \\\n#     --weights yolov5s6.pt \\\n#     --name cots_with_albs \\\n#     --hyp data/hyps/hyp.heavy.2.yaml \\\n#     --save-period 1","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:59:22.420691Z","iopub.execute_input":"2022-02-10T20:59:22.420917Z","iopub.status.idle":"2022-02-10T20:59:22.427415Z","shell.execute_reply.started":"2022-02-10T20:59:22.420887Z","shell.execute_reply":"2022-02-10T20:59:22.426674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:59:22.429098Z","iopub.execute_input":"2022-02-10T20:59:22.430125Z","iopub.status.idle":"2022-02-10T20:59:23.084692Z","shell.execute_reply.started":"2022-02-10T20:59:22.430099Z","shell.execute_reply":"2022-02-10T20:59:23.083885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\n\n!cp -r /kaggle/working/yolov5/runs/train/base_vid_2val /kaggle/working\n\n!cp /kaggle/working/yolov5/data/reef_f1_naive.yaml /kaggle/working/base_vid_2val/\n!cp /kaggle/working/yolov5/data/hyps/hyp.heavy.2.yaml /kaggle/working/base_vid_2val/\n# !cp /kaggle/working/yolov5/utils/augmentations.py /kaggle/working/base_vid_2val/\n\n!rm -r /kaggle/working/yolov5\n!rm -r /kaggle/working/images\n!rm -r /kaggle/working/labels\n!rm -r /kaggle/working/yolo_data","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:59:23.087292Z","iopub.execute_input":"2022-02-10T20:59:23.087935Z","iopub.status.idle":"2022-02-10T20:59:27.066381Z","shell.execute_reply.started":"2022-02-10T20:59:23.087899Z","shell.execute_reply":"2022-02-10T20:59:27.065562Z"},"trusted":true},"execution_count":null,"outputs":[]}]}