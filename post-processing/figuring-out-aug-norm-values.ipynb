{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3ed6f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T09:44:54.203254Z",
     "iopub.status.busy": "2022-01-25T09:44:54.201356Z",
     "iopub.status.idle": "2022-01-25T09:44:58.149585Z",
     "shell.execute_reply": "2022-01-25T09:44:58.148932Z",
     "shell.execute_reply.started": "2022-01-25T09:28:23.181879Z"
    },
    "papermill": {
     "duration": 3.968801,
     "end_time": "2022-01-25T09:44:58.149757",
     "exception": false,
     "start_time": "2022-01-25T09:44:54.180956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "from skimage import io\n",
    "import torchvision\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import utils\n",
    "import albumentations as A\n",
    "from albumentations import (HorizontalFlip, ShiftScaleRotate, VerticalFlip, Normalize,Flip,\n",
    "                            Compose, GaussNoise)\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = DEVICE\n",
    "BASE_DIR = \"../input/tensorflow-great-barrier-reef/train_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988805b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T09:44:58.178868Z",
     "iopub.status.busy": "2022-01-25T09:44:58.178236Z",
     "iopub.status.idle": "2022-01-25T09:44:58.477848Z",
     "shell.execute_reply": "2022-01-25T09:44:58.478331Z",
     "shell.execute_reply.started": "2022-01-25T09:28:27.430914Z"
    },
    "papermill": {
     "duration": 0.31751,
     "end_time": "2022-01-25T09:44:58.478502",
     "exception": false,
     "start_time": "2022-01-25T09:44:58.160992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>sequence_frame</th>\n",
       "      <th>image_id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>img_path</th>\n",
       "      <th>no_of_bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0-16</td>\n",
       "      <td>[{'x': 559, 'y': 213, 'width': 50, 'height': 32}]</td>\n",
       "      <td>video_0/16.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0-17</td>\n",
       "      <td>[{'x': 558, 'y': 213, 'width': 50, 'height': 32}]</td>\n",
       "      <td>video_0/17.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0-18</td>\n",
       "      <td>[{'x': 557, 'y': 213, 'width': 50, 'height': 32}]</td>\n",
       "      <td>video_0/18.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0-19</td>\n",
       "      <td>[{'x': 556, 'y': 214, 'width': 50, 'height': 32}]</td>\n",
       "      <td>video_0/19.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>[{'x': 555, 'y': 214, 'width': 50, 'height': 32}]</td>\n",
       "      <td>video_0/20.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  sequence  video_frame  sequence_frame image_id  \\\n",
       "0         0     40258           16              16     0-16   \n",
       "1         0     40258           17              17     0-17   \n",
       "2         0     40258           18              18     0-18   \n",
       "3         0     40258           19              19     0-19   \n",
       "4         0     40258           20              20     0-20   \n",
       "\n",
       "                                         annotations        img_path  \\\n",
       "0  [{'x': 559, 'y': 213, 'width': 50, 'height': 32}]  video_0/16.jpg   \n",
       "1  [{'x': 558, 'y': 213, 'width': 50, 'height': 32}]  video_0/17.jpg   \n",
       "2  [{'x': 557, 'y': 213, 'width': 50, 'height': 32}]  video_0/18.jpg   \n",
       "3  [{'x': 556, 'y': 214, 'width': 50, 'height': 32}]  video_0/19.jpg   \n",
       "4  [{'x': 555, 'y': 214, 'width': 50, 'height': 32}]  video_0/20.jpg   \n",
       "\n",
       "   no_of_bbox  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/tensorflow-great-barrier-reef/train.csv\")\n",
    "# train_df['annotations'].iloc[3]\n",
    "train_df['annotations'] = train_df['annotations'].apply(eval)\n",
    "func = lambda x: \"video_\"+x.split(\"-\")[0]+\"/\"+x.split(\"-\")[1]+\".jpg\"\n",
    "# vid_func = lambda x: \"video_\"+x.split(\"-\")[0]\n",
    "\n",
    "train_df[\"img_path\"] = train_df[\"image_id\"].apply(func)\n",
    "# train_df[\"vid_path\"] = train_df[\"image_id\"].apply(vid_func)\n",
    "# train_df.head()\n",
    "train_df[\"no_of_bbox\"] = train_df[\"annotations\"].apply(lambda x: len(x))\n",
    "train_df = train_df[train_df[\"no_of_bbox\"]>0].reset_index(drop=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d4c3ab",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-25T09:44:58.507368Z",
     "iopub.status.busy": "2022-01-25T09:44:58.503986Z",
     "iopub.status.idle": "2022-01-25T09:44:58.519641Z",
     "shell.execute_reply": "2022-01-25T09:44:58.519032Z",
     "shell.execute_reply.started": "2022-01-25T09:28:27.809790Z"
    },
    "papermill": {
     "duration": 0.029569,
     "end_time": "2022-01-25T09:44:58.519783",
     "exception": false,
     "start_time": "2022-01-25T09:44:58.490214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReefDataset:\n",
    "\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def can_augment(self, boxes):\n",
    "        box_outside_image = ((boxes[:, 0] < 0).any() or (boxes[:, 1] < 0).any() \n",
    "                             or (boxes[:, 2] > 1280).any() or (boxes[:, 3] > 720).any())\n",
    "        return not box_outside_image\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        row = self.df.iloc[i]\n",
    "        \n",
    "        image = cv2.imread(f'{BASE_DIR}/{row[\"img_path\"]}', cv2.IMREAD_COLOR)\n",
    "#         print(f'{BASE_DIR}/{row[\"img_path\"]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float)\n",
    "        image /=255.0\n",
    "        \n",
    "        \n",
    "        boxes = pd.DataFrame(row['annotations'], columns=['x', 'y', 'width', 'height']).astype(np.float).values\n",
    "        \n",
    "        # Change from [x_min, y_min, w, h] to [x_min, y_min, x_max, y_max]\n",
    "#         boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "#         boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        boxes[:, 2] = np.clip(boxes[:, 0] + boxes[:, 2],0,1280)\n",
    "        boxes[:, 3] = np.clip(boxes[:, 1] + boxes[:, 3],0,720)\n",
    "        \n",
    "        n_boxes = boxes.shape[0]\n",
    "        \n",
    "        # Calculate the area\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        \n",
    "        \n",
    "        target = {\n",
    "            'boxes': torch.as_tensor(boxes, dtype=torch.float32),\n",
    "            'area': torch.as_tensor(area, dtype=torch.float32),\n",
    "            \n",
    "            'image_id': torch.tensor([i]),\n",
    "            \n",
    "            \n",
    "            'labels': torch.ones((n_boxes,), dtype=torch.int64),\n",
    "            \n",
    "            \n",
    "            'iscrowd': torch.zeros((n_boxes,), dtype=torch.int64)            \n",
    "        }\n",
    "\n",
    "        if self.transforms and self.can_augment(boxes):\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': target['labels']\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "            \n",
    "            if n_boxes > 0:\n",
    "                target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "        else:\n",
    "            image = ToTensorV2(p=1.0)(image=image)['image']\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495a3f41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T09:44:58.547081Z",
     "iopub.status.busy": "2022-01-25T09:44:58.546132Z",
     "iopub.status.idle": "2022-01-25T09:44:58.548970Z",
     "shell.execute_reply": "2022-01-25T09:44:58.548397Z",
     "shell.execute_reply.started": "2022-01-25T09:28:27.831990Z"
    },
    "papermill": {
     "duration": 0.018236,
     "end_time": "2022-01-25T09:44:58.549101",
     "exception": false,
     "start_time": "2022-01-25T09:44:58.530865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_train = train_df.iloc[0: 4427]\n",
    "# df_val = train_df.iloc[4428:4918]\n",
    "\n",
    "# ds_train = ReefDataset(df_train)\n",
    "# ds_val = ReefDataset(df_val)\n",
    "\n",
    "ds_train = ReefDataset(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a525030a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T09:44:58.574966Z",
     "iopub.status.busy": "2022-01-25T09:44:58.573890Z",
     "iopub.status.idle": "2022-01-25T09:44:58.578582Z",
     "shell.execute_reply": "2022-01-25T09:44:58.579105Z",
     "shell.execute_reply.started": "2022-01-25T09:28:27.845905Z"
    },
    "papermill": {
     "duration": 0.019269,
     "end_time": "2022-01-25T09:44:58.579312",
     "exception": false,
     "start_time": "2022-01-25T09:44:58.560043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=1, shuffle=False, num_workers=4, collate_fn=collate_fn)\n",
    "# dl_val = DataLoader(ds_val, batch_size=2, shuffle=False, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d1f01d1",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-25T09:44:58.606116Z",
     "iopub.status.busy": "2022-01-25T09:44:58.605508Z",
     "iopub.status.idle": "2022-01-25T09:44:58.607116Z",
     "shell.execute_reply": "2022-01-25T09:44:58.607611Z",
     "shell.execute_reply.started": "2022-01-25T09:28:27.857289Z"
    },
    "papermill": {
     "duration": 0.017341,
     "end_time": "2022-01-25T09:44:58.607771",
     "exception": false,
     "start_time": "2022-01-25T09:44:58.590430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4bf6b50",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-25T09:44:58.633016Z",
     "iopub.status.busy": "2022-01-25T09:44:58.632410Z",
     "iopub.status.idle": "2022-01-25T09:44:58.635740Z",
     "shell.execute_reply": "2022-01-25T09:44:58.636286Z",
     "shell.execute_reply.started": "2022-01-25T09:28:27.873492Z"
    },
    "papermill": {
     "duration": 0.017633,
     "end_time": "2022-01-25T09:44:58.636479",
     "exception": false,
     "start_time": "2022-01-25T09:44:58.618846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# mean = 0.\n",
    "# std = 0.\n",
    "# nb_samples = 0.\n",
    "# for i in tqdm(range(len(ds_train))):\n",
    "# #     for data in dl_train:\n",
    "#     batch_samples = ds_train[i][0].size(0)\n",
    "#     data = ds_train[i][0].view(batch_samples, ds_train[i][0].size(1), -1)\n",
    "#     mean += data.mean(2).sum(0)\n",
    "#     std += data.std(2).sum(0)\n",
    "#     nb_samples += batch_samples\n",
    "\n",
    "# mean /= nb_samples\n",
    "# std /= nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bb58de6",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-25T09:44:58.661993Z",
     "iopub.status.busy": "2022-01-25T09:44:58.661398Z",
     "iopub.status.idle": "2022-01-25T09:44:58.665347Z",
     "shell.execute_reply": "2022-01-25T09:44:58.665785Z",
     "shell.execute_reply.started": "2022-01-25T09:28:27.884164Z"
    },
    "papermill": {
     "duration": 0.01835,
     "end_time": "2022-01-25T09:44:58.665950",
     "exception": false,
     "start_time": "2022-01-25T09:44:58.647600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torchvision.transforms as transforms\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# img = plt.imread(\"../input/tensorflow-great-barrier-reef/train_images/video_0/1007.jpg\")\n",
    "\n",
    "\n",
    "# def get_train_transform():\n",
    "#     return A.Compose([\n",
    "#         ToTensorV2(p=1.0)\n",
    "#     ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "# # transform = transforms.Compose([\n",
    "# #     transforms.ToTensor()\n",
    "# # ])\n",
    "\n",
    "# transform =  A.Compose([\n",
    "#         ToTensorV2(p=1.0)\n",
    "#     ])\n",
    "# # , bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']}\n",
    "# sample = {'image': img}\n",
    "# # print(*sample)\n",
    "# sample = transforms(**sample)\n",
    "# # image = sample['image']\n",
    "# # # transform the pIL image to tensor \n",
    "# # # image\n",
    "# # img_tr = transform(img)\n",
    "\n",
    "# # # calculate mean and std\n",
    "# # mean, std = img_tr.mean([1,2]), img_tr.std([1,2])\n",
    "  \n",
    "# # # print mean and std\n",
    "# # print(\"mean and std before normalize:\")\n",
    "# # print(\"Mean of the image:\", mean)\n",
    "# # print(\"Std of the image:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9e5f46f",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-25T09:44:58.692053Z",
     "iopub.status.busy": "2022-01-25T09:44:58.690660Z",
     "iopub.status.idle": "2022-01-25T09:44:58.694733Z",
     "shell.execute_reply": "2022-01-25T09:44:58.694291Z",
     "shell.execute_reply.started": "2022-01-25T09:28:27.895054Z"
    },
    "papermill": {
     "duration": 0.017907,
     "end_time": "2022-01-25T09:44:58.694886",
     "exception": false,
     "start_time": "2022-01-25T09:44:58.676979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image = cv2.imread(\"../input/tensorflow-great-barrier-reef/train_images/video_0/1007.jpg\").astype(np.float) / 255.0\n",
    "\n",
    "# transform = A.Compose([\n",
    "#      ToTensorV2(p=1.0)\n",
    "# ])\n",
    "\n",
    "# transformed = transform(image=image)[\"image\"] # shape [chn,height,width]\n",
    "# mean, std = transformed.mean([1,2]), transformed.std([1,2])\n",
    "\n",
    "# # print mean and std\n",
    "# print(\"mean and std before normalize:\")\n",
    "# print(\"Mean of the image:\", mean)\n",
    "# print(\"Std of the image:\", std)\n",
    "# # plt.imshow(transformed.permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee975f8a",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-25T09:44:58.720944Z",
     "iopub.status.busy": "2022-01-25T09:44:58.720382Z",
     "iopub.status.idle": "2022-01-25T09:44:58.722642Z",
     "shell.execute_reply": "2022-01-25T09:44:58.723100Z",
     "shell.execute_reply.started": "2022-01-25T09:28:27.906031Z"
    },
    "papermill": {
     "duration": 0.017318,
     "end_time": "2022-01-25T09:44:58.723275",
     "exception": false,
     "start_time": "2022-01-25T09:44:58.705957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transformed.mean([1,2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adbd1588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T09:44:58.752026Z",
     "iopub.status.busy": "2022-01-25T09:44:58.748122Z",
     "iopub.status.idle": "2022-01-25T09:49:57.213495Z",
     "shell.execute_reply": "2022-01-25T09:49:57.213924Z",
     "shell.execute_reply.started": "2022-01-25T09:28:27.921195Z"
    },
    "papermill": {
     "duration": 298.479855,
     "end_time": "2022-01-25T09:49:57.214107",
     "exception": false,
     "start_time": "2022-01-25T09:44:58.734252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4919/4919 [04:58<00:00, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and std before normalize:\n",
      "Mean of the image: [0.22246136 0.57680758 0.65816097]\n",
      "Std of the image: [0.17461663 0.17586531 0.1624069 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = A.Compose([\n",
    "     ToTensorV2(p=1.0)\n",
    "])\n",
    "\n",
    "mean_list = []\n",
    "std_list = []\n",
    "for i in tqdm(range(len(ds_train))):\n",
    "    img = ds_train[i][0].numpy()\n",
    "#     print(img.shape)\n",
    "#     break\n",
    "    transformed = transform(image=img)[\"image\"] # shape [chn,height,width]\n",
    "    mean, std = transformed.mean([0,2]).tolist(), transformed.std([0,2]).tolist()\n",
    "#     print(transformed.mean([0,2]).shape)\n",
    "#     break\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    \n",
    "# print mean and std\n",
    "print(\"mean and std before normalize:\")\n",
    "print(\"Mean of the image:\", np.mean(mean_list,axis=0))\n",
    "print(\"Std of the image:\", np.mean(std_list,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8d49a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T09:49:58.399756Z",
     "iopub.status.busy": "2022-01-25T09:49:58.398732Z",
     "iopub.status.idle": "2022-01-25T09:49:58.416876Z",
     "shell.execute_reply": "2022-01-25T09:49:58.417405Z",
     "shell.execute_reply.started": "2022-01-25T09:43:33.221926Z"
    },
    "papermill": {
     "duration": 0.60313,
     "end_time": "2022-01-25T09:49:58.417585",
     "exception": false,
     "start_time": "2022-01-25T09:49:57.814455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and std before normalize:\n",
      "Mean of the image: [0.222, 0.577, 0.658]\n",
      "Std of the image: [0.175, 0.176, 0.162]\n"
     ]
    }
   ],
   "source": [
    "# print mean and std\n",
    "print(\"mean and std before normalize:\")\n",
    "print(\"Mean of the image:\", [np.round_(i,3) for i in np.mean(mean_list,axis=0)])\n",
    "print(\"Std of the image:\", [np.round_(i,3) for i in np.mean(std_list,axis=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e314488",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-25T09:49:59.553966Z",
     "iopub.status.busy": "2022-01-25T09:49:59.553207Z",
     "iopub.status.idle": "2022-01-25T09:49:59.556093Z",
     "shell.execute_reply": "2022-01-25T09:49:59.555613Z",
     "shell.execute_reply.started": "2022-01-25T09:33:41.716809Z"
    },
    "papermill": {
     "duration": 0.574589,
     "end_time": "2022-01-25T09:49:59.556267",
     "exception": false,
     "start_time": "2022-01-25T09:49:58.981678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lst = [[0.6644307981004902, 0.5943366140727124, 0.20642771735430285],\n",
    "#       [0.6644307981004902, 0.5943366140727124, 0.20642771735430285],\n",
    "#       [0.6644307981004902, 0.5943366140727124, 0.20642771735430285],\n",
    "#       [0.6644307981004902, 0.5943366140727124, 0.20642771735430285],\n",
    "#       [0.6644307981004902, 0.5943366140727124, 0.20642771735430285]]\n",
    "\n",
    "# np.mean(lst,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f7f61d3",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-25T09:50:00.684628Z",
     "iopub.status.busy": "2022-01-25T09:50:00.684003Z",
     "iopub.status.idle": "2022-01-25T09:50:00.686876Z",
     "shell.execute_reply": "2022-01-25T09:50:00.687381Z",
     "shell.execute_reply.started": "2022-01-25T09:33:41.727768Z"
    },
    "papermill": {
     "duration": 0.569294,
     "end_time": "2022-01-25T09:50:00.687556",
     "exception": false,
     "start_time": "2022-01-25T09:50:00.118262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ds_train[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d49b87",
   "metadata": {
    "papermill": {
     "duration": 0.558642,
     "end_time": "2022-01-25T09:50:01.870777",
     "exception": false,
     "start_time": "2022-01-25T09:50:01.312135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0555254",
   "metadata": {
    "papermill": {
     "duration": 0.560478,
     "end_time": "2022-01-25T09:50:02.995373",
     "exception": false,
     "start_time": "2022-01-25T09:50:02.434895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 318.666945,
   "end_time": "2022-01-25T09:50:04.465032",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-25T09:44:45.798087",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
